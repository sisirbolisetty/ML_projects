{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from librosa import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data loaded. Loading time: 209.822203874588 seconds ---\n"
     ]
    }
   ],
   "source": [
    "file_path = '/home/sisir/BDA/ravdess/'\n",
    "lst = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for subdir, dirs, files in os.walk(file_path):\n",
    "  for file in files:\n",
    "      try:\n",
    "        # Load a librosa array, obtain mfcss,mel, chroma features store the file and all information in a new arrays\n",
    "        X, sample_rate = librosa.load(os.file_path.join(subdir,file), res_type='kaiser_fast')\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
    "        mel = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T,axis=0)\n",
    "        stft = np.abs(librosa.stft(X))\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "        # The code below converts the labels starting from 1 to 8 to a series from 0 to 7\n",
    "        # This is because the predictor needs to start from 0 otherwise it will try to predict 0 also.\n",
    "        file = int(file[7:8]) - 1 \n",
    "        mfccs_mel_features = np.hstack((mfccs,mel))\n",
    "        mfccs_mel_chroma_features = np.hstack((mfccs_mel_features,chroma))\n",
    "        arr = mfccs_mel_chroma_features, file\n",
    "        lst.append(arr)\n",
    "    \n",
    "      # If the file is not valid, below code skip's it\n",
    "      except ValueError:\n",
    "        continue\n",
    "# print(mfccs.shape)\n",
    "# print(mel.shape)\n",
    "# print(arr)\n",
    "# print(len(arr))\n",
    "print(\"--- Data has loaded and the Loading time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = zip(*lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1440, 180), (1440,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.15      0.11        27\n",
      "           1       0.44      0.46      0.45        57\n",
      "           2       0.24      0.23      0.23        57\n",
      "           3       0.18      0.21      0.20        56\n",
      "           4       0.53      0.49      0.51        55\n",
      "           5       0.40      0.38      0.39        61\n",
      "           6       0.28      0.24      0.26        62\n",
      "           7       0.35      0.30      0.32        57\n",
      "\n",
      "    accuracy                           0.32       432\n",
      "   macro avg       0.32      0.31      0.31       432\n",
      "weighted avg       0.33      0.32      0.32       432\n",
      "\n",
      "[[ 4  4  2 14  1  0  1  1]\n",
      " [12 26  1 11  1  3  2  1]\n",
      " [ 4  3 13  4  6 12  9  6]\n",
      " [10 16  5 12  1  2  4  6]\n",
      " [ 0  0  6  3 27  7  5  7]\n",
      " [ 2  2  8  8  3 23 11  4]\n",
      " [ 7  5  6 10  8  5 15  6]\n",
      " [ 4  3 14  4  4  5  6 17]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rforest = RandomForestClassifier(criterion=\"gini\", max_depth=10, max_features=\"log2\", \n",
    "                                 max_leaf_nodes = 100, min_samples_leaf = 3, min_samples_split = 20, \n",
    "                                 n_estimators= 22000, random_state= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=10, max_features='log2',\n",
       "                       max_leaf_nodes=100, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=3, min_samples_split=20,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=22000,\n",
       "                       n_jobs=None, oob_score=False, random_state=5, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rforest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rforest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.07      0.12        27\n",
      "           1       0.48      0.84      0.62        57\n",
      "           2       0.47      0.35      0.40        57\n",
      "           3       0.33      0.29      0.31        56\n",
      "           4       0.68      0.55      0.61        55\n",
      "           5       0.46      0.31      0.37        61\n",
      "           6       0.47      0.56      0.51        62\n",
      "           7       0.39      0.51      0.44        57\n",
      "\n",
      "    accuracy                           0.46       432\n",
      "   macro avg       0.45      0.44      0.42       432\n",
      "weighted avg       0.46      0.46      0.44       432\n",
      "\n",
      "[[ 2 14  5  4  0  0  1  1]\n",
      " [ 0 48  0  4  0  0  4  1]\n",
      " [ 1  2 20  2  3 11  5 13]\n",
      " [ 0 19  2 16  0  6  9  4]\n",
      " [ 0  1  1  0 30  1  9 13]\n",
      " [ 1  2  6 12  7 19  5  9]\n",
      " [ 0 11  6  3  1  1 35  5]\n",
      " [ 3  2  3  7  3  3  7 29]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution Neural Networks\n",
    "\n",
    "x_traincnn = np.expand_dims(X_train, axis=2)\n",
    "x_testcnn = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1008, 180, 1), (432, 180, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_traincnn.shape, x_testcnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/sisir/envs/Dissertation/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sisir/envs/Dissertation/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sisir/envs/Dissertation/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sisir/envs/Dissertation/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sisir/envs/Dissertation/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sisir/envs/Dissertation/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/sisir/envs/Dissertation/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sisir/envs/Dissertation/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sisir/envs/Dissertation/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sisir/envs/Dissertation/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sisir/envs/Dissertation/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sisir/envs/Dissertation/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sisir/envs/Dissertation/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same', input_shape=(180,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.rmsprop(lr=0.005, rho=0.9, decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 180, 128)          768       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 180, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 180, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 22, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2816)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 22536     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 105,352\n",
      "Trainable params: 105,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1008, 180, 1), (1008,), (432, 180, 1), (432,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_traincnn.shape, y_train.shape, x_testcnn.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sisir/envs/Dissertation/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1008 samples, validate on 432 samples\n",
      "Epoch 1/1000\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: 10.1311 - accuracy: 0.1954 - val_loss: 1.9289 - val_accuracy: 0.2269\n",
      "Epoch 2/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.7820 - accuracy: 0.2986 - val_loss: 1.8567 - val_accuracy: 0.3241\n",
      "Epoch 3/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.6872 - accuracy: 0.3532 - val_loss: 1.7886 - val_accuracy: 0.3565\n",
      "Epoch 4/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.6177 - accuracy: 0.4018 - val_loss: 1.7426 - val_accuracy: 0.3611\n",
      "Epoch 5/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.5925 - accuracy: 0.3879 - val_loss: 1.7214 - val_accuracy: 0.3843\n",
      "Epoch 6/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.5527 - accuracy: 0.4167 - val_loss: 1.7205 - val_accuracy: 0.3796\n",
      "Epoch 7/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.4984 - accuracy: 0.4435 - val_loss: 1.7257 - val_accuracy: 0.3657\n",
      "Epoch 8/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.4646 - accuracy: 0.4464 - val_loss: 1.7181 - val_accuracy: 0.3843\n",
      "Epoch 9/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.4247 - accuracy: 0.4702 - val_loss: 1.6959 - val_accuracy: 0.4282\n",
      "Epoch 10/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.4172 - accuracy: 0.4772 - val_loss: 1.6928 - val_accuracy: 0.3958\n",
      "Epoch 11/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.3803 - accuracy: 0.4940 - val_loss: 1.6838 - val_accuracy: 0.4190\n",
      "Epoch 12/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.3636 - accuracy: 0.4742 - val_loss: 1.7134 - val_accuracy: 0.4028\n",
      "Epoch 13/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.3386 - accuracy: 0.5060 - val_loss: 1.6760 - val_accuracy: 0.4468\n",
      "Epoch 14/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.3163 - accuracy: 0.5040 - val_loss: 1.7033 - val_accuracy: 0.3935\n",
      "Epoch 15/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.2938 - accuracy: 0.5129 - val_loss: 1.6909 - val_accuracy: 0.4282\n",
      "Epoch 16/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 1.2784 - accuracy: 0.5208 - val_loss: 1.6775 - val_accuracy: 0.4560\n",
      "Epoch 17/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.2472 - accuracy: 0.5407 - val_loss: 1.6850 - val_accuracy: 0.4398\n",
      "Epoch 18/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.2340 - accuracy: 0.5258 - val_loss: 1.6827 - val_accuracy: 0.4398\n",
      "Epoch 19/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.2264 - accuracy: 0.5516 - val_loss: 1.6833 - val_accuracy: 0.4421\n",
      "Epoch 20/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.1918 - accuracy: 0.5685 - val_loss: 1.7035 - val_accuracy: 0.4583\n",
      "Epoch 21/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.1939 - accuracy: 0.5575 - val_loss: 1.6707 - val_accuracy: 0.4630\n",
      "Epoch 22/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.1791 - accuracy: 0.5476 - val_loss: 1.6953 - val_accuracy: 0.4306\n",
      "Epoch 23/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.1579 - accuracy: 0.5754 - val_loss: 1.6713 - val_accuracy: 0.4630\n",
      "Epoch 24/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.1701 - accuracy: 0.5685 - val_loss: 1.6725 - val_accuracy: 0.4907\n",
      "Epoch 25/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.1407 - accuracy: 0.5853 - val_loss: 1.6693 - val_accuracy: 0.4884\n",
      "Epoch 26/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.1093 - accuracy: 0.6032 - val_loss: 1.6811 - val_accuracy: 0.4722\n",
      "Epoch 27/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.1209 - accuracy: 0.5903 - val_loss: 1.6675 - val_accuracy: 0.4699\n",
      "Epoch 28/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.1120 - accuracy: 0.5903 - val_loss: 1.6811 - val_accuracy: 0.4931\n",
      "Epoch 29/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.0969 - accuracy: 0.5962 - val_loss: 1.6916 - val_accuracy: 0.4861\n",
      "Epoch 30/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.0673 - accuracy: 0.6012 - val_loss: 1.6914 - val_accuracy: 0.4931\n",
      "Epoch 31/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.0998 - accuracy: 0.5992 - val_loss: 1.6903 - val_accuracy: 0.4931\n",
      "Epoch 32/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.0710 - accuracy: 0.6131 - val_loss: 1.6832 - val_accuracy: 0.4884\n",
      "Epoch 33/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.0510 - accuracy: 0.6300 - val_loss: 1.6812 - val_accuracy: 0.4884\n",
      "Epoch 34/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.0520 - accuracy: 0.6171 - val_loss: 1.6726 - val_accuracy: 0.4884\n",
      "Epoch 35/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.0595 - accuracy: 0.6190 - val_loss: 1.6691 - val_accuracy: 0.4838\n",
      "Epoch 36/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.0292 - accuracy: 0.6429 - val_loss: 1.6753 - val_accuracy: 0.4769\n",
      "Epoch 37/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.0385 - accuracy: 0.6260 - val_loss: 1.6709 - val_accuracy: 0.4907\n",
      "Epoch 38/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.0199 - accuracy: 0.6359 - val_loss: 1.6677 - val_accuracy: 0.5023\n",
      "Epoch 39/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.0214 - accuracy: 0.6310 - val_loss: 1.6739 - val_accuracy: 0.4954\n",
      "Epoch 40/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.0040 - accuracy: 0.6359 - val_loss: 1.6659 - val_accuracy: 0.4931\n",
      "Epoch 41/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.0055 - accuracy: 0.6369 - val_loss: 1.6634 - val_accuracy: 0.5162\n",
      "Epoch 42/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 1.0040 - accuracy: 0.6339 - val_loss: 1.6505 - val_accuracy: 0.5069\n",
      "Epoch 43/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 1.0033 - accuracy: 0.6448 - val_loss: 1.6680 - val_accuracy: 0.4977\n",
      "Epoch 44/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.9910 - accuracy: 0.6369 - val_loss: 1.6701 - val_accuracy: 0.5046\n",
      "Epoch 45/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.9822 - accuracy: 0.6577 - val_loss: 1.6566 - val_accuracy: 0.5000\n",
      "Epoch 46/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.9818 - accuracy: 0.6488 - val_loss: 1.6683 - val_accuracy: 0.5139\n",
      "Epoch 47/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.9564 - accuracy: 0.6508 - val_loss: 1.6755 - val_accuracy: 0.5162\n",
      "Epoch 48/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.9678 - accuracy: 0.6696 - val_loss: 1.6831 - val_accuracy: 0.5162\n",
      "Epoch 49/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.9826 - accuracy: 0.6627 - val_loss: 1.6509 - val_accuracy: 0.5208\n",
      "Epoch 50/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.9521 - accuracy: 0.6558 - val_loss: 1.6602 - val_accuracy: 0.4815\n",
      "Epoch 51/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.9534 - accuracy: 0.6637 - val_loss: 1.6720 - val_accuracy: 0.5069\n",
      "Epoch 52/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.9535 - accuracy: 0.6706 - val_loss: 1.6709 - val_accuracy: 0.5116\n",
      "Epoch 53/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.9338 - accuracy: 0.6756 - val_loss: 1.6662 - val_accuracy: 0.5000\n",
      "Epoch 54/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.9536 - accuracy: 0.6716 - val_loss: 1.6476 - val_accuracy: 0.5116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.9515 - accuracy: 0.6696 - val_loss: 1.6660 - val_accuracy: 0.5023\n",
      "Epoch 56/1000\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: 0.9252 - accuracy: 0.6865 - val_loss: 1.6652 - val_accuracy: 0.5185\n",
      "Epoch 57/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.9207 - accuracy: 0.6796 - val_loss: 1.6637 - val_accuracy: 0.5139\n",
      "Epoch 58/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.9253 - accuracy: 0.6825 - val_loss: 1.6668 - val_accuracy: 0.5185\n",
      "Epoch 59/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.9223 - accuracy: 0.6885 - val_loss: 1.6617 - val_accuracy: 0.5116\n",
      "Epoch 60/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.9032 - accuracy: 0.6855 - val_loss: 1.6540 - val_accuracy: 0.5255\n",
      "Epoch 61/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.9153 - accuracy: 0.6736 - val_loss: 1.6603 - val_accuracy: 0.5116\n",
      "Epoch 62/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.8843 - accuracy: 0.6845 - val_loss: 1.6623 - val_accuracy: 0.5255\n",
      "Epoch 63/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.8943 - accuracy: 0.6944 - val_loss: 1.6565 - val_accuracy: 0.5278\n",
      "Epoch 64/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.8842 - accuracy: 0.6984 - val_loss: 1.6690 - val_accuracy: 0.5255\n",
      "Epoch 65/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.8985 - accuracy: 0.6875 - val_loss: 1.6505 - val_accuracy: 0.5208\n",
      "Epoch 66/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.8586 - accuracy: 0.7014 - val_loss: 1.6624 - val_accuracy: 0.5255\n",
      "Epoch 67/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.9017 - accuracy: 0.6766 - val_loss: 1.6492 - val_accuracy: 0.5394\n",
      "Epoch 68/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.8589 - accuracy: 0.7093 - val_loss: 1.6476 - val_accuracy: 0.5370\n",
      "Epoch 69/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.8700 - accuracy: 0.6974 - val_loss: 1.6581 - val_accuracy: 0.5324\n",
      "Epoch 70/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.8791 - accuracy: 0.6825 - val_loss: 1.6611 - val_accuracy: 0.5069\n",
      "Epoch 71/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.8756 - accuracy: 0.6905 - val_loss: 1.6624 - val_accuracy: 0.5278\n",
      "Epoch 72/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.8938 - accuracy: 0.7014 - val_loss: 1.6582 - val_accuracy: 0.5278\n",
      "Epoch 73/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.8705 - accuracy: 0.7034 - val_loss: 1.6484 - val_accuracy: 0.5278\n",
      "Epoch 74/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.8857 - accuracy: 0.6825 - val_loss: 1.6513 - val_accuracy: 0.5301\n",
      "Epoch 75/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.8651 - accuracy: 0.6905 - val_loss: 1.6388 - val_accuracy: 0.5301\n",
      "Epoch 76/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.8596 - accuracy: 0.7014 - val_loss: 1.6436 - val_accuracy: 0.5208\n",
      "Epoch 77/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.8481 - accuracy: 0.6994 - val_loss: 1.6581 - val_accuracy: 0.5255\n",
      "Epoch 78/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.8359 - accuracy: 0.7163 - val_loss: 1.6511 - val_accuracy: 0.5208\n",
      "Epoch 79/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.8309 - accuracy: 0.7014 - val_loss: 1.6504 - val_accuracy: 0.5208\n",
      "Epoch 80/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.8428 - accuracy: 0.7054 - val_loss: 1.6584 - val_accuracy: 0.5370\n",
      "Epoch 81/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.8580 - accuracy: 0.6905 - val_loss: 1.6589 - val_accuracy: 0.5278\n",
      "Epoch 82/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.8363 - accuracy: 0.7212 - val_loss: 1.6604 - val_accuracy: 0.5278\n",
      "Epoch 83/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.8123 - accuracy: 0.7133 - val_loss: 1.6662 - val_accuracy: 0.5324\n",
      "Epoch 84/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.8312 - accuracy: 0.7044 - val_loss: 1.6572 - val_accuracy: 0.5417\n",
      "Epoch 85/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.8370 - accuracy: 0.7014 - val_loss: 1.6463 - val_accuracy: 0.5370\n",
      "Epoch 86/1000\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: 0.8272 - accuracy: 0.7113 - val_loss: 1.6612 - val_accuracy: 0.5301\n",
      "Epoch 87/1000\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: 0.8064 - accuracy: 0.7272 - val_loss: 1.6736 - val_accuracy: 0.5231\n",
      "Epoch 88/1000\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: 0.8345 - accuracy: 0.7083 - val_loss: 1.6652 - val_accuracy: 0.5440\n",
      "Epoch 89/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.8048 - accuracy: 0.7173 - val_loss: 1.6642 - val_accuracy: 0.5278\n",
      "Epoch 90/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.8185 - accuracy: 0.7242 - val_loss: 1.6560 - val_accuracy: 0.5486\n",
      "Epoch 91/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.8373 - accuracy: 0.7103 - val_loss: 1.6610 - val_accuracy: 0.5255\n",
      "Epoch 92/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7930 - accuracy: 0.7361 - val_loss: 1.6564 - val_accuracy: 0.5301\n",
      "Epoch 93/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.8137 - accuracy: 0.7044 - val_loss: 1.6626 - val_accuracy: 0.5301\n",
      "Epoch 94/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.8247 - accuracy: 0.7153 - val_loss: 1.6611 - val_accuracy: 0.5278\n",
      "Epoch 95/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.8029 - accuracy: 0.7232 - val_loss: 1.6574 - val_accuracy: 0.5370\n",
      "Epoch 96/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.8308 - accuracy: 0.7133 - val_loss: 1.6530 - val_accuracy: 0.5370\n",
      "Epoch 97/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.8079 - accuracy: 0.7173 - val_loss: 1.6593 - val_accuracy: 0.5347\n",
      "Epoch 98/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.8172 - accuracy: 0.7133 - val_loss: 1.6571 - val_accuracy: 0.5255\n",
      "Epoch 99/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.8026 - accuracy: 0.7232 - val_loss: 1.6522 - val_accuracy: 0.5324\n",
      "Epoch 100/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7857 - accuracy: 0.7232 - val_loss: 1.6609 - val_accuracy: 0.5440\n",
      "Epoch 101/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.8145 - accuracy: 0.7222 - val_loss: 1.6670 - val_accuracy: 0.5301\n",
      "Epoch 102/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7780 - accuracy: 0.7371 - val_loss: 1.6565 - val_accuracy: 0.5463\n",
      "Epoch 103/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7790 - accuracy: 0.7331 - val_loss: 1.6578 - val_accuracy: 0.5394\n",
      "Epoch 104/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7938 - accuracy: 0.7212 - val_loss: 1.6602 - val_accuracy: 0.5255\n",
      "Epoch 105/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7784 - accuracy: 0.7272 - val_loss: 1.6642 - val_accuracy: 0.5370\n",
      "Epoch 106/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7979 - accuracy: 0.7212 - val_loss: 1.6655 - val_accuracy: 0.5347\n",
      "Epoch 107/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7761 - accuracy: 0.7391 - val_loss: 1.6511 - val_accuracy: 0.5324\n",
      "Epoch 108/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7643 - accuracy: 0.7292 - val_loss: 1.6556 - val_accuracy: 0.5370\n",
      "Epoch 109/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7932 - accuracy: 0.7292 - val_loss: 1.6594 - val_accuracy: 0.5440\n",
      "Epoch 110/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.8057 - accuracy: 0.7242 - val_loss: 1.6477 - val_accuracy: 0.5255\n",
      "Epoch 111/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7770 - accuracy: 0.7351 - val_loss: 1.6425 - val_accuracy: 0.5417\n",
      "Epoch 112/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7733 - accuracy: 0.7391 - val_loss: 1.6428 - val_accuracy: 0.5440\n",
      "Epoch 113/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7669 - accuracy: 0.7302 - val_loss: 1.6423 - val_accuracy: 0.5486\n",
      "Epoch 114/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7659 - accuracy: 0.7262 - val_loss: 1.6408 - val_accuracy: 0.5278\n",
      "Epoch 115/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7771 - accuracy: 0.7272 - val_loss: 1.6347 - val_accuracy: 0.5370\n",
      "Epoch 116/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7616 - accuracy: 0.7381 - val_loss: 1.6527 - val_accuracy: 0.5370\n",
      "Epoch 117/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7738 - accuracy: 0.7321 - val_loss: 1.6588 - val_accuracy: 0.5324\n",
      "Epoch 118/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.7720 - accuracy: 0.7351 - val_loss: 1.6608 - val_accuracy: 0.5417\n",
      "Epoch 119/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7437 - accuracy: 0.7450 - val_loss: 1.6419 - val_accuracy: 0.5463\n",
      "Epoch 120/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7364 - accuracy: 0.7401 - val_loss: 1.6535 - val_accuracy: 0.5370\n",
      "Epoch 121/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7522 - accuracy: 0.7232 - val_loss: 1.6551 - val_accuracy: 0.5417\n",
      "Epoch 122/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7724 - accuracy: 0.7312 - val_loss: 1.6481 - val_accuracy: 0.5440\n",
      "Epoch 123/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7542 - accuracy: 0.7431 - val_loss: 1.6513 - val_accuracy: 0.5347\n",
      "Epoch 124/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7548 - accuracy: 0.7460 - val_loss: 1.6595 - val_accuracy: 0.5347\n",
      "Epoch 125/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7503 - accuracy: 0.7490 - val_loss: 1.6627 - val_accuracy: 0.5370\n",
      "Epoch 126/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7484 - accuracy: 0.7470 - val_loss: 1.6579 - val_accuracy: 0.5301\n",
      "Epoch 127/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7385 - accuracy: 0.7361 - val_loss: 1.6536 - val_accuracy: 0.5324\n",
      "Epoch 128/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7587 - accuracy: 0.7440 - val_loss: 1.6488 - val_accuracy: 0.5440\n",
      "Epoch 129/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7197 - accuracy: 0.7450 - val_loss: 1.6499 - val_accuracy: 0.5394\n",
      "Epoch 130/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7568 - accuracy: 0.7450 - val_loss: 1.6535 - val_accuracy: 0.5370\n",
      "Epoch 131/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7341 - accuracy: 0.7510 - val_loss: 1.6514 - val_accuracy: 0.5347\n",
      "Epoch 132/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7423 - accuracy: 0.7569 - val_loss: 1.6465 - val_accuracy: 0.5417\n",
      "Epoch 133/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7300 - accuracy: 0.7470 - val_loss: 1.6478 - val_accuracy: 0.5301\n",
      "Epoch 134/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7274 - accuracy: 0.7530 - val_loss: 1.6560 - val_accuracy: 0.5301\n",
      "Epoch 135/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7531 - accuracy: 0.7312 - val_loss: 1.6556 - val_accuracy: 0.5394\n",
      "Epoch 136/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7428 - accuracy: 0.7411 - val_loss: 1.6492 - val_accuracy: 0.5556\n",
      "Epoch 137/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7252 - accuracy: 0.7401 - val_loss: 1.6565 - val_accuracy: 0.5440\n",
      "Epoch 138/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.7295 - accuracy: 0.7599 - val_loss: 1.6544 - val_accuracy: 0.5463\n",
      "Epoch 139/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7482 - accuracy: 0.7540 - val_loss: 1.6617 - val_accuracy: 0.5509\n",
      "Epoch 140/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7200 - accuracy: 0.7530 - val_loss: 1.6598 - val_accuracy: 0.5463\n",
      "Epoch 141/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7569 - accuracy: 0.7480 - val_loss: 1.6446 - val_accuracy: 0.5417\n",
      "Epoch 142/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7251 - accuracy: 0.7460 - val_loss: 1.6421 - val_accuracy: 0.5347\n",
      "Epoch 143/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7250 - accuracy: 0.7520 - val_loss: 1.6513 - val_accuracy: 0.5347\n",
      "Epoch 144/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7269 - accuracy: 0.7510 - val_loss: 1.6515 - val_accuracy: 0.5324\n",
      "Epoch 145/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7112 - accuracy: 0.7639 - val_loss: 1.6445 - val_accuracy: 0.5440\n",
      "Epoch 146/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7170 - accuracy: 0.7530 - val_loss: 1.6521 - val_accuracy: 0.5509\n",
      "Epoch 147/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7385 - accuracy: 0.7550 - val_loss: 1.6434 - val_accuracy: 0.5394\n",
      "Epoch 148/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7012 - accuracy: 0.7718 - val_loss: 1.6462 - val_accuracy: 0.5486\n",
      "Epoch 149/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7228 - accuracy: 0.7371 - val_loss: 1.6429 - val_accuracy: 0.5463\n",
      "Epoch 150/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6926 - accuracy: 0.7718 - val_loss: 1.6416 - val_accuracy: 0.5463\n",
      "Epoch 151/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7009 - accuracy: 0.7560 - val_loss: 1.6463 - val_accuracy: 0.5347\n",
      "Epoch 152/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7001 - accuracy: 0.7589 - val_loss: 1.6440 - val_accuracy: 0.5417\n",
      "Epoch 153/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6966 - accuracy: 0.7540 - val_loss: 1.6518 - val_accuracy: 0.5440\n",
      "Epoch 154/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7062 - accuracy: 0.7560 - val_loss: 1.6465 - val_accuracy: 0.5509\n",
      "Epoch 155/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7249 - accuracy: 0.7510 - val_loss: 1.6512 - val_accuracy: 0.5324\n",
      "Epoch 156/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7100 - accuracy: 0.7530 - val_loss: 1.6534 - val_accuracy: 0.5463\n",
      "Epoch 157/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7066 - accuracy: 0.7629 - val_loss: 1.6650 - val_accuracy: 0.5417\n",
      "Epoch 158/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7032 - accuracy: 0.7619 - val_loss: 1.6616 - val_accuracy: 0.5440\n",
      "Epoch 159/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6979 - accuracy: 0.7718 - val_loss: 1.6525 - val_accuracy: 0.5440\n",
      "Epoch 160/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7006 - accuracy: 0.7639 - val_loss: 1.6612 - val_accuracy: 0.5532\n",
      "Epoch 161/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7133 - accuracy: 0.7688 - val_loss: 1.6673 - val_accuracy: 0.5463\n",
      "Epoch 162/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6969 - accuracy: 0.7500 - val_loss: 1.6727 - val_accuracy: 0.5394\n",
      "Epoch 163/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6851 - accuracy: 0.7669 - val_loss: 1.6625 - val_accuracy: 0.5394\n",
      "Epoch 164/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.7124 - accuracy: 0.7669 - val_loss: 1.6590 - val_accuracy: 0.5463\n",
      "Epoch 165/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7045 - accuracy: 0.7639 - val_loss: 1.6574 - val_accuracy: 0.5417\n",
      "Epoch 166/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7124 - accuracy: 0.7500 - val_loss: 1.6603 - val_accuracy: 0.5532\n",
      "Epoch 167/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7039 - accuracy: 0.7589 - val_loss: 1.6617 - val_accuracy: 0.5509\n",
      "Epoch 168/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6896 - accuracy: 0.7659 - val_loss: 1.6693 - val_accuracy: 0.5532\n",
      "Epoch 169/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6824 - accuracy: 0.7629 - val_loss: 1.6633 - val_accuracy: 0.5417\n",
      "Epoch 170/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6885 - accuracy: 0.7639 - val_loss: 1.6618 - val_accuracy: 0.5440\n",
      "Epoch 171/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6922 - accuracy: 0.7530 - val_loss: 1.6631 - val_accuracy: 0.5532\n",
      "Epoch 172/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7017 - accuracy: 0.7510 - val_loss: 1.6690 - val_accuracy: 0.5509\n",
      "Epoch 173/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6959 - accuracy: 0.7639 - val_loss: 1.6724 - val_accuracy: 0.5394\n",
      "Epoch 174/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6901 - accuracy: 0.7738 - val_loss: 1.6634 - val_accuracy: 0.5440\n",
      "Epoch 175/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7002 - accuracy: 0.7649 - val_loss: 1.6610 - val_accuracy: 0.5463\n",
      "Epoch 176/1000\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: 0.6862 - accuracy: 0.7579 - val_loss: 1.6624 - val_accuracy: 0.5417\n",
      "Epoch 177/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6831 - accuracy: 0.7629 - val_loss: 1.6748 - val_accuracy: 0.5394\n",
      "Epoch 178/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6895 - accuracy: 0.7609 - val_loss: 1.6722 - val_accuracy: 0.5440\n",
      "Epoch 179/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7024 - accuracy: 0.7609 - val_loss: 1.6677 - val_accuracy: 0.5486\n",
      "Epoch 180/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7033 - accuracy: 0.7550 - val_loss: 1.6678 - val_accuracy: 0.5486\n",
      "Epoch 181/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6873 - accuracy: 0.7569 - val_loss: 1.6646 - val_accuracy: 0.5486\n",
      "Epoch 182/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6883 - accuracy: 0.7718 - val_loss: 1.6761 - val_accuracy: 0.5440\n",
      "Epoch 183/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6856 - accuracy: 0.7688 - val_loss: 1.6726 - val_accuracy: 0.5532\n",
      "Epoch 184/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7086 - accuracy: 0.7589 - val_loss: 1.6663 - val_accuracy: 0.5509\n",
      "Epoch 185/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6572 - accuracy: 0.7877 - val_loss: 1.6671 - val_accuracy: 0.5440\n",
      "Epoch 186/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7006 - accuracy: 0.7639 - val_loss: 1.6626 - val_accuracy: 0.5509\n",
      "Epoch 187/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6857 - accuracy: 0.7639 - val_loss: 1.6641 - val_accuracy: 0.5509\n",
      "Epoch 188/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6693 - accuracy: 0.7698 - val_loss: 1.6562 - val_accuracy: 0.5509\n",
      "Epoch 189/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.7003 - accuracy: 0.7550 - val_loss: 1.6573 - val_accuracy: 0.5556\n",
      "Epoch 190/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6721 - accuracy: 0.7669 - val_loss: 1.6619 - val_accuracy: 0.5694\n",
      "Epoch 191/1000\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: 0.6600 - accuracy: 0.7728 - val_loss: 1.6651 - val_accuracy: 0.5532\n",
      "Epoch 192/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6799 - accuracy: 0.7649 - val_loss: 1.6719 - val_accuracy: 0.5509\n",
      "Epoch 193/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6941 - accuracy: 0.7599 - val_loss: 1.6750 - val_accuracy: 0.5463\n",
      "Epoch 194/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6755 - accuracy: 0.7649 - val_loss: 1.6757 - val_accuracy: 0.5556\n",
      "Epoch 195/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6756 - accuracy: 0.7758 - val_loss: 1.6686 - val_accuracy: 0.5486\n",
      "Epoch 196/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6464 - accuracy: 0.7808 - val_loss: 1.6772 - val_accuracy: 0.5556\n",
      "Epoch 197/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6609 - accuracy: 0.7808 - val_loss: 1.6698 - val_accuracy: 0.5532\n",
      "Epoch 198/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6776 - accuracy: 0.7629 - val_loss: 1.6672 - val_accuracy: 0.5417\n",
      "Epoch 199/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6638 - accuracy: 0.7758 - val_loss: 1.6661 - val_accuracy: 0.5486\n",
      "Epoch 200/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6796 - accuracy: 0.7540 - val_loss: 1.6626 - val_accuracy: 0.5463\n",
      "Epoch 201/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6748 - accuracy: 0.7569 - val_loss: 1.6638 - val_accuracy: 0.5532\n",
      "Epoch 202/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6749 - accuracy: 0.7599 - val_loss: 1.6674 - val_accuracy: 0.5602\n",
      "Epoch 203/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6581 - accuracy: 0.7778 - val_loss: 1.6694 - val_accuracy: 0.5532\n",
      "Epoch 204/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6823 - accuracy: 0.7579 - val_loss: 1.6688 - val_accuracy: 0.5532\n",
      "Epoch 205/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6767 - accuracy: 0.7748 - val_loss: 1.6710 - val_accuracy: 0.5509\n",
      "Epoch 206/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6832 - accuracy: 0.7659 - val_loss: 1.6736 - val_accuracy: 0.5579\n",
      "Epoch 207/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6669 - accuracy: 0.7788 - val_loss: 1.6692 - val_accuracy: 0.5556\n",
      "Epoch 208/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6494 - accuracy: 0.7867 - val_loss: 1.6801 - val_accuracy: 0.5509\n",
      "Epoch 209/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6700 - accuracy: 0.7728 - val_loss: 1.6790 - val_accuracy: 0.5463\n",
      "Epoch 210/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6539 - accuracy: 0.7847 - val_loss: 1.6735 - val_accuracy: 0.5532\n",
      "Epoch 211/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6502 - accuracy: 0.7887 - val_loss: 1.6771 - val_accuracy: 0.5440\n",
      "Epoch 212/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6404 - accuracy: 0.7857 - val_loss: 1.6796 - val_accuracy: 0.5509\n",
      "Epoch 213/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6590 - accuracy: 0.7619 - val_loss: 1.6755 - val_accuracy: 0.5556\n",
      "Epoch 214/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6702 - accuracy: 0.7768 - val_loss: 1.6724 - val_accuracy: 0.5556\n",
      "Epoch 215/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6623 - accuracy: 0.7718 - val_loss: 1.6755 - val_accuracy: 0.5532\n",
      "Epoch 216/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6420 - accuracy: 0.7778 - val_loss: 1.6762 - val_accuracy: 0.5556\n",
      "Epoch 217/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6473 - accuracy: 0.7738 - val_loss: 1.6844 - val_accuracy: 0.5509\n",
      "Epoch 218/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6443 - accuracy: 0.7659 - val_loss: 1.6795 - val_accuracy: 0.5532\n",
      "Epoch 219/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6594 - accuracy: 0.7907 - val_loss: 1.6709 - val_accuracy: 0.5532\n",
      "Epoch 220/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6528 - accuracy: 0.7887 - val_loss: 1.6777 - val_accuracy: 0.5509\n",
      "Epoch 221/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6389 - accuracy: 0.7808 - val_loss: 1.6749 - val_accuracy: 0.5509\n",
      "Epoch 222/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.6700 - accuracy: 0.7817 - val_loss: 1.6693 - val_accuracy: 0.5556\n",
      "Epoch 223/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.6419 - accuracy: 0.7857 - val_loss: 1.6710 - val_accuracy: 0.5509\n",
      "Epoch 224/1000\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: 0.6729 - accuracy: 0.7560 - val_loss: 1.6724 - val_accuracy: 0.5509\n",
      "Epoch 225/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6627 - accuracy: 0.7728 - val_loss: 1.6696 - val_accuracy: 0.5556\n",
      "Epoch 226/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.6417 - accuracy: 0.7817 - val_loss: 1.6750 - val_accuracy: 0.5509\n",
      "Epoch 227/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6501 - accuracy: 0.7738 - val_loss: 1.6753 - val_accuracy: 0.5509\n",
      "Epoch 228/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6647 - accuracy: 0.7728 - val_loss: 1.6700 - val_accuracy: 0.5556\n",
      "Epoch 229/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6610 - accuracy: 0.7907 - val_loss: 1.6637 - val_accuracy: 0.5532\n",
      "Epoch 230/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6545 - accuracy: 0.7649 - val_loss: 1.6677 - val_accuracy: 0.5556\n",
      "Epoch 231/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6624 - accuracy: 0.7688 - val_loss: 1.6642 - val_accuracy: 0.5556\n",
      "Epoch 232/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6320 - accuracy: 0.7867 - val_loss: 1.6682 - val_accuracy: 0.5556\n",
      "Epoch 233/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6463 - accuracy: 0.7788 - val_loss: 1.6721 - val_accuracy: 0.5509\n",
      "Epoch 234/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6336 - accuracy: 0.7897 - val_loss: 1.6709 - val_accuracy: 0.5532\n",
      "Epoch 235/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6504 - accuracy: 0.7728 - val_loss: 1.6723 - val_accuracy: 0.5532\n",
      "Epoch 236/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6274 - accuracy: 0.7917 - val_loss: 1.6736 - val_accuracy: 0.5602\n",
      "Epoch 237/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6647 - accuracy: 0.7827 - val_loss: 1.6678 - val_accuracy: 0.5486\n",
      "Epoch 238/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6331 - accuracy: 0.7937 - val_loss: 1.6764 - val_accuracy: 0.5579\n",
      "Epoch 239/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6327 - accuracy: 0.7887 - val_loss: 1.6732 - val_accuracy: 0.5509\n",
      "Epoch 240/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6521 - accuracy: 0.7698 - val_loss: 1.6689 - val_accuracy: 0.5532\n",
      "Epoch 241/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6222 - accuracy: 0.7996 - val_loss: 1.6673 - val_accuracy: 0.5509\n",
      "Epoch 242/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6603 - accuracy: 0.7728 - val_loss: 1.6652 - val_accuracy: 0.5579\n",
      "Epoch 243/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6307 - accuracy: 0.7758 - val_loss: 1.6701 - val_accuracy: 0.5509\n",
      "Epoch 244/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6224 - accuracy: 0.7867 - val_loss: 1.6730 - val_accuracy: 0.5486\n",
      "Epoch 245/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6109 - accuracy: 0.7927 - val_loss: 1.6684 - val_accuracy: 0.5509\n",
      "Epoch 246/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6416 - accuracy: 0.7837 - val_loss: 1.6680 - val_accuracy: 0.5509\n",
      "Epoch 247/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6742 - accuracy: 0.7728 - val_loss: 1.6709 - val_accuracy: 0.5509\n",
      "Epoch 248/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6516 - accuracy: 0.7738 - val_loss: 1.6623 - val_accuracy: 0.5463\n",
      "Epoch 249/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6362 - accuracy: 0.7758 - val_loss: 1.6678 - val_accuracy: 0.5579\n",
      "Epoch 250/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6414 - accuracy: 0.7688 - val_loss: 1.6674 - val_accuracy: 0.5509\n",
      "Epoch 251/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6448 - accuracy: 0.7907 - val_loss: 1.6710 - val_accuracy: 0.5556\n",
      "Epoch 252/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6375 - accuracy: 0.7867 - val_loss: 1.6756 - val_accuracy: 0.5509\n",
      "Epoch 253/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6236 - accuracy: 0.7867 - val_loss: 1.6686 - val_accuracy: 0.5532\n",
      "Epoch 254/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6219 - accuracy: 0.7798 - val_loss: 1.6699 - val_accuracy: 0.5532\n",
      "Epoch 255/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6292 - accuracy: 0.7847 - val_loss: 1.6695 - val_accuracy: 0.5556\n",
      "Epoch 256/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6492 - accuracy: 0.7837 - val_loss: 1.6725 - val_accuracy: 0.5509\n",
      "Epoch 257/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5932 - accuracy: 0.8036 - val_loss: 1.6710 - val_accuracy: 0.5602\n",
      "Epoch 258/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6256 - accuracy: 0.7827 - val_loss: 1.6758 - val_accuracy: 0.5579\n",
      "Epoch 259/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6286 - accuracy: 0.7927 - val_loss: 1.6768 - val_accuracy: 0.5648\n",
      "Epoch 260/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6546 - accuracy: 0.7788 - val_loss: 1.6763 - val_accuracy: 0.5556\n",
      "Epoch 261/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6318 - accuracy: 0.7827 - val_loss: 1.6811 - val_accuracy: 0.5532\n",
      "Epoch 262/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6312 - accuracy: 0.7937 - val_loss: 1.6769 - val_accuracy: 0.5532\n",
      "Epoch 263/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6665 - accuracy: 0.7768 - val_loss: 1.6764 - val_accuracy: 0.5486\n",
      "Epoch 264/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6208 - accuracy: 0.7946 - val_loss: 1.6755 - val_accuracy: 0.5509\n",
      "Epoch 265/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6720 - accuracy: 0.7748 - val_loss: 1.6753 - val_accuracy: 0.5556\n",
      "Epoch 266/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6414 - accuracy: 0.7837 - val_loss: 1.6735 - val_accuracy: 0.5602\n",
      "Epoch 267/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6210 - accuracy: 0.7897 - val_loss: 1.6755 - val_accuracy: 0.5486\n",
      "Epoch 268/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5981 - accuracy: 0.7867 - val_loss: 1.6730 - val_accuracy: 0.5532\n",
      "Epoch 269/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.6268 - accuracy: 0.7798 - val_loss: 1.6819 - val_accuracy: 0.5556\n",
      "Epoch 270/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6103 - accuracy: 0.8016 - val_loss: 1.6794 - val_accuracy: 0.5486\n",
      "Epoch 271/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6242 - accuracy: 0.7847 - val_loss: 1.6745 - val_accuracy: 0.5509\n",
      "Epoch 272/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6016 - accuracy: 0.8016 - val_loss: 1.6829 - val_accuracy: 0.5417\n",
      "Epoch 273/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6204 - accuracy: 0.7837 - val_loss: 1.6820 - val_accuracy: 0.5532\n",
      "Epoch 274/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6169 - accuracy: 0.7867 - val_loss: 1.6808 - val_accuracy: 0.5509\n",
      "Epoch 275/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6260 - accuracy: 0.7887 - val_loss: 1.6750 - val_accuracy: 0.5509\n",
      "Epoch 276/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6488 - accuracy: 0.7937 - val_loss: 1.6794 - val_accuracy: 0.5486\n",
      "Epoch 277/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6209 - accuracy: 0.7956 - val_loss: 1.6769 - val_accuracy: 0.5486\n",
      "Epoch 278/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6254 - accuracy: 0.7917 - val_loss: 1.6707 - val_accuracy: 0.5463\n",
      "Epoch 279/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6130 - accuracy: 0.8145 - val_loss: 1.6828 - val_accuracy: 0.5440\n",
      "Epoch 280/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6200 - accuracy: 0.7897 - val_loss: 1.6762 - val_accuracy: 0.5509\n",
      "Epoch 281/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6289 - accuracy: 0.7798 - val_loss: 1.6761 - val_accuracy: 0.5556\n",
      "Epoch 282/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6302 - accuracy: 0.7907 - val_loss: 1.6732 - val_accuracy: 0.5509\n",
      "Epoch 283/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6364 - accuracy: 0.7708 - val_loss: 1.6750 - val_accuracy: 0.5417\n",
      "Epoch 284/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6088 - accuracy: 0.8006 - val_loss: 1.6744 - val_accuracy: 0.5509\n",
      "Epoch 285/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5978 - accuracy: 0.7907 - val_loss: 1.6721 - val_accuracy: 0.5463\n",
      "Epoch 286/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6137 - accuracy: 0.7897 - val_loss: 1.6740 - val_accuracy: 0.5532\n",
      "Epoch 287/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6252 - accuracy: 0.7986 - val_loss: 1.6761 - val_accuracy: 0.5463\n",
      "Epoch 288/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6051 - accuracy: 0.8036 - val_loss: 1.6754 - val_accuracy: 0.5509\n",
      "Epoch 289/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6100 - accuracy: 0.7976 - val_loss: 1.6840 - val_accuracy: 0.5486\n",
      "Epoch 290/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6012 - accuracy: 0.7887 - val_loss: 1.6721 - val_accuracy: 0.5532\n",
      "Epoch 291/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6273 - accuracy: 0.7827 - val_loss: 1.6727 - val_accuracy: 0.5556\n",
      "Epoch 292/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5963 - accuracy: 0.7966 - val_loss: 1.6725 - val_accuracy: 0.5486\n",
      "Epoch 293/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5987 - accuracy: 0.7887 - val_loss: 1.6744 - val_accuracy: 0.5602\n",
      "Epoch 294/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5969 - accuracy: 0.8006 - val_loss: 1.6803 - val_accuracy: 0.5509\n",
      "Epoch 295/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6138 - accuracy: 0.7956 - val_loss: 1.6792 - val_accuracy: 0.5602\n",
      "Epoch 296/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6241 - accuracy: 0.7857 - val_loss: 1.6792 - val_accuracy: 0.5625\n",
      "Epoch 297/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6019 - accuracy: 0.7867 - val_loss: 1.6848 - val_accuracy: 0.5440\n",
      "Epoch 298/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6200 - accuracy: 0.7877 - val_loss: 1.6879 - val_accuracy: 0.5579\n",
      "Epoch 299/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6069 - accuracy: 0.7927 - val_loss: 1.6902 - val_accuracy: 0.5486\n",
      "Epoch 300/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5989 - accuracy: 0.7937 - val_loss: 1.6901 - val_accuracy: 0.5579\n",
      "Epoch 301/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6092 - accuracy: 0.7966 - val_loss: 1.6926 - val_accuracy: 0.5579\n",
      "Epoch 302/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6013 - accuracy: 0.7956 - val_loss: 1.6887 - val_accuracy: 0.5602\n",
      "Epoch 303/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6292 - accuracy: 0.7827 - val_loss: 1.6828 - val_accuracy: 0.5532\n",
      "Epoch 304/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6101 - accuracy: 0.7837 - val_loss: 1.6853 - val_accuracy: 0.5532\n",
      "Epoch 305/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6184 - accuracy: 0.7798 - val_loss: 1.6821 - val_accuracy: 0.5602\n",
      "Epoch 306/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5933 - accuracy: 0.8016 - val_loss: 1.6902 - val_accuracy: 0.5625\n",
      "Epoch 307/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6212 - accuracy: 0.7907 - val_loss: 1.6892 - val_accuracy: 0.5556\n",
      "Epoch 308/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6124 - accuracy: 0.7897 - val_loss: 1.6888 - val_accuracy: 0.5509\n",
      "Epoch 309/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6045 - accuracy: 0.8016 - val_loss: 1.6894 - val_accuracy: 0.5579\n",
      "Epoch 310/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6091 - accuracy: 0.7917 - val_loss: 1.6847 - val_accuracy: 0.5671\n",
      "Epoch 311/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6082 - accuracy: 0.7956 - val_loss: 1.6858 - val_accuracy: 0.5671\n",
      "Epoch 312/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6342 - accuracy: 0.7758 - val_loss: 1.6867 - val_accuracy: 0.5602\n",
      "Epoch 313/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5785 - accuracy: 0.8016 - val_loss: 1.6877 - val_accuracy: 0.5532\n",
      "Epoch 314/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5886 - accuracy: 0.7966 - val_loss: 1.6838 - val_accuracy: 0.5602\n",
      "Epoch 315/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6195 - accuracy: 0.7827 - val_loss: 1.6812 - val_accuracy: 0.5532\n",
      "Epoch 316/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5820 - accuracy: 0.8006 - val_loss: 1.6859 - val_accuracy: 0.5602\n",
      "Epoch 317/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5912 - accuracy: 0.7996 - val_loss: 1.6911 - val_accuracy: 0.5625\n",
      "Epoch 318/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5995 - accuracy: 0.8056 - val_loss: 1.6901 - val_accuracy: 0.5556\n",
      "Epoch 319/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5743 - accuracy: 0.8026 - val_loss: 1.6860 - val_accuracy: 0.5556\n",
      "Epoch 320/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6124 - accuracy: 0.7976 - val_loss: 1.6827 - val_accuracy: 0.5625\n",
      "Epoch 321/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5977 - accuracy: 0.7917 - val_loss: 1.6784 - val_accuracy: 0.5556\n",
      "Epoch 322/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6094 - accuracy: 0.8006 - val_loss: 1.6813 - val_accuracy: 0.5602\n",
      "Epoch 323/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5822 - accuracy: 0.8056 - val_loss: 1.6839 - val_accuracy: 0.5579\n",
      "Epoch 324/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6089 - accuracy: 0.7956 - val_loss: 1.6897 - val_accuracy: 0.5532\n",
      "Epoch 325/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5692 - accuracy: 0.8036 - val_loss: 1.6890 - val_accuracy: 0.5509\n",
      "Epoch 326/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6017 - accuracy: 0.8006 - val_loss: 1.6880 - val_accuracy: 0.5486\n",
      "Epoch 327/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6144 - accuracy: 0.7927 - val_loss: 1.6916 - val_accuracy: 0.5579\n",
      "Epoch 328/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5927 - accuracy: 0.8085 - val_loss: 1.6879 - val_accuracy: 0.5625\n",
      "Epoch 329/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6000 - accuracy: 0.7887 - val_loss: 1.6876 - val_accuracy: 0.5764\n",
      "Epoch 330/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6048 - accuracy: 0.7857 - val_loss: 1.6891 - val_accuracy: 0.5671\n",
      "Epoch 331/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5868 - accuracy: 0.7867 - val_loss: 1.6932 - val_accuracy: 0.5648\n",
      "Epoch 332/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5994 - accuracy: 0.7887 - val_loss: 1.6892 - val_accuracy: 0.5556\n",
      "Epoch 333/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6083 - accuracy: 0.7788 - val_loss: 1.6928 - val_accuracy: 0.5579\n",
      "Epoch 334/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5885 - accuracy: 0.8016 - val_loss: 1.6903 - val_accuracy: 0.5556\n",
      "Epoch 335/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5851 - accuracy: 0.7917 - val_loss: 1.6875 - val_accuracy: 0.5579\n",
      "Epoch 336/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5852 - accuracy: 0.8085 - val_loss: 1.6884 - val_accuracy: 0.5532\n",
      "Epoch 337/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6035 - accuracy: 0.7907 - val_loss: 1.6918 - val_accuracy: 0.5556\n",
      "Epoch 338/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5832 - accuracy: 0.8075 - val_loss: 1.6919 - val_accuracy: 0.5694\n",
      "Epoch 339/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5906 - accuracy: 0.7976 - val_loss: 1.6987 - val_accuracy: 0.5532\n",
      "Epoch 340/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5804 - accuracy: 0.7986 - val_loss: 1.6925 - val_accuracy: 0.5556\n",
      "Epoch 341/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5948 - accuracy: 0.7867 - val_loss: 1.6945 - val_accuracy: 0.5556\n",
      "Epoch 342/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6030 - accuracy: 0.7976 - val_loss: 1.6896 - val_accuracy: 0.5579\n",
      "Epoch 343/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5747 - accuracy: 0.8085 - val_loss: 1.6918 - val_accuracy: 0.5648\n",
      "Epoch 344/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6090 - accuracy: 0.7817 - val_loss: 1.7005 - val_accuracy: 0.5602\n",
      "Epoch 345/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5796 - accuracy: 0.8006 - val_loss: 1.6984 - val_accuracy: 0.5648\n",
      "Epoch 346/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5887 - accuracy: 0.8006 - val_loss: 1.6960 - val_accuracy: 0.5648\n",
      "Epoch 347/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5895 - accuracy: 0.7887 - val_loss: 1.6983 - val_accuracy: 0.5694\n",
      "Epoch 348/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5827 - accuracy: 0.7946 - val_loss: 1.6946 - val_accuracy: 0.5602\n",
      "Epoch 349/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5756 - accuracy: 0.8135 - val_loss: 1.6994 - val_accuracy: 0.5579\n",
      "Epoch 350/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5793 - accuracy: 0.8085 - val_loss: 1.7021 - val_accuracy: 0.5625\n",
      "Epoch 351/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5676 - accuracy: 0.8145 - val_loss: 1.7010 - val_accuracy: 0.5602\n",
      "Epoch 352/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6014 - accuracy: 0.7827 - val_loss: 1.6986 - val_accuracy: 0.5602\n",
      "Epoch 353/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5755 - accuracy: 0.8056 - val_loss: 1.6936 - val_accuracy: 0.5602\n",
      "Epoch 354/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5931 - accuracy: 0.7956 - val_loss: 1.6958 - val_accuracy: 0.5625\n",
      "Epoch 355/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5639 - accuracy: 0.8175 - val_loss: 1.6948 - val_accuracy: 0.5625\n",
      "Epoch 356/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6000 - accuracy: 0.7837 - val_loss: 1.7003 - val_accuracy: 0.5648\n",
      "Epoch 357/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5688 - accuracy: 0.8224 - val_loss: 1.6985 - val_accuracy: 0.5602\n",
      "Epoch 358/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5909 - accuracy: 0.8046 - val_loss: 1.7016 - val_accuracy: 0.5648\n",
      "Epoch 359/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5933 - accuracy: 0.7976 - val_loss: 1.7019 - val_accuracy: 0.5694\n",
      "Epoch 360/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5931 - accuracy: 0.7956 - val_loss: 1.6995 - val_accuracy: 0.5718\n",
      "Epoch 361/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5761 - accuracy: 0.8036 - val_loss: 1.6989 - val_accuracy: 0.5602\n",
      "Epoch 362/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5760 - accuracy: 0.8214 - val_loss: 1.6992 - val_accuracy: 0.5579\n",
      "Epoch 363/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5833 - accuracy: 0.8006 - val_loss: 1.6990 - val_accuracy: 0.5648\n",
      "Epoch 364/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5616 - accuracy: 0.8185 - val_loss: 1.7000 - val_accuracy: 0.5648\n",
      "Epoch 365/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5963 - accuracy: 0.8026 - val_loss: 1.6982 - val_accuracy: 0.5694\n",
      "Epoch 366/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5572 - accuracy: 0.8175 - val_loss: 1.7004 - val_accuracy: 0.5648\n",
      "Epoch 367/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5882 - accuracy: 0.8075 - val_loss: 1.6955 - val_accuracy: 0.5625\n",
      "Epoch 368/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5977 - accuracy: 0.7857 - val_loss: 1.7020 - val_accuracy: 0.5602\n",
      "Epoch 369/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5808 - accuracy: 0.7907 - val_loss: 1.7001 - val_accuracy: 0.5579\n",
      "Epoch 370/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5653 - accuracy: 0.8125 - val_loss: 1.6977 - val_accuracy: 0.5671\n",
      "Epoch 371/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5766 - accuracy: 0.8115 - val_loss: 1.6978 - val_accuracy: 0.5532\n",
      "Epoch 372/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.6037 - accuracy: 0.7798 - val_loss: 1.6958 - val_accuracy: 0.5625\n",
      "Epoch 373/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5811 - accuracy: 0.8085 - val_loss: 1.6958 - val_accuracy: 0.5625\n",
      "Epoch 374/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5760 - accuracy: 0.8115 - val_loss: 1.6938 - val_accuracy: 0.5648\n",
      "Epoch 375/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5749 - accuracy: 0.8105 - val_loss: 1.6968 - val_accuracy: 0.5648\n",
      "Epoch 376/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5623 - accuracy: 0.7946 - val_loss: 1.6958 - val_accuracy: 0.5648\n",
      "Epoch 377/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5820 - accuracy: 0.8056 - val_loss: 1.6951 - val_accuracy: 0.5694\n",
      "Epoch 378/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5570 - accuracy: 0.8194 - val_loss: 1.6939 - val_accuracy: 0.5648\n",
      "Epoch 379/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5897 - accuracy: 0.7907 - val_loss: 1.6864 - val_accuracy: 0.5579\n",
      "Epoch 380/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5735 - accuracy: 0.8204 - val_loss: 1.6919 - val_accuracy: 0.5671\n",
      "Epoch 381/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5742 - accuracy: 0.8056 - val_loss: 1.6896 - val_accuracy: 0.5648\n",
      "Epoch 382/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5720 - accuracy: 0.7946 - val_loss: 1.6916 - val_accuracy: 0.5579\n",
      "Epoch 383/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5662 - accuracy: 0.8085 - val_loss: 1.6977 - val_accuracy: 0.5625\n",
      "Epoch 384/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.5696 - accuracy: 0.8056 - val_loss: 1.6941 - val_accuracy: 0.5602\n",
      "Epoch 385/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5733 - accuracy: 0.7956 - val_loss: 1.6934 - val_accuracy: 0.5694\n",
      "Epoch 386/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5493 - accuracy: 0.8254 - val_loss: 1.6967 - val_accuracy: 0.5625\n",
      "Epoch 387/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5763 - accuracy: 0.7927 - val_loss: 1.7009 - val_accuracy: 0.5718\n",
      "Epoch 388/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5662 - accuracy: 0.8056 - val_loss: 1.6949 - val_accuracy: 0.5648\n",
      "Epoch 389/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5748 - accuracy: 0.8026 - val_loss: 1.6936 - val_accuracy: 0.5602\n",
      "Epoch 390/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5545 - accuracy: 0.8016 - val_loss: 1.6952 - val_accuracy: 0.5579\n",
      "Epoch 391/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5498 - accuracy: 0.8165 - val_loss: 1.6949 - val_accuracy: 0.5648\n",
      "Epoch 392/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5713 - accuracy: 0.8036 - val_loss: 1.6909 - val_accuracy: 0.5625\n",
      "Epoch 393/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5827 - accuracy: 0.7986 - val_loss: 1.6928 - val_accuracy: 0.5648\n",
      "Epoch 394/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5464 - accuracy: 0.8155 - val_loss: 1.6991 - val_accuracy: 0.5718\n",
      "Epoch 395/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5645 - accuracy: 0.8105 - val_loss: 1.6956 - val_accuracy: 0.5694\n",
      "Epoch 396/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5503 - accuracy: 0.7996 - val_loss: 1.7001 - val_accuracy: 0.5694\n",
      "Epoch 397/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5778 - accuracy: 0.8105 - val_loss: 1.6962 - val_accuracy: 0.5648\n",
      "Epoch 398/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5687 - accuracy: 0.8125 - val_loss: 1.6984 - val_accuracy: 0.5602\n",
      "Epoch 399/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5719 - accuracy: 0.8006 - val_loss: 1.6965 - val_accuracy: 0.5579\n",
      "Epoch 400/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5772 - accuracy: 0.8016 - val_loss: 1.7011 - val_accuracy: 0.5602\n",
      "Epoch 401/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5683 - accuracy: 0.7976 - val_loss: 1.7015 - val_accuracy: 0.5648\n",
      "Epoch 402/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.8244 - val_loss: 1.7032 - val_accuracy: 0.5625\n",
      "Epoch 403/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5634 - accuracy: 0.8026 - val_loss: 1.7064 - val_accuracy: 0.5671\n",
      "Epoch 404/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5714 - accuracy: 0.8085 - val_loss: 1.7052 - val_accuracy: 0.5671\n",
      "Epoch 405/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5374 - accuracy: 0.8264 - val_loss: 1.7014 - val_accuracy: 0.5694\n",
      "Epoch 406/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5683 - accuracy: 0.8056 - val_loss: 1.7044 - val_accuracy: 0.5648\n",
      "Epoch 407/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5786 - accuracy: 0.8026 - val_loss: 1.7014 - val_accuracy: 0.5648\n",
      "Epoch 408/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5762 - accuracy: 0.8075 - val_loss: 1.7030 - val_accuracy: 0.5602\n",
      "Epoch 409/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5713 - accuracy: 0.8115 - val_loss: 1.7060 - val_accuracy: 0.5625\n",
      "Epoch 410/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.7937 - val_loss: 1.7043 - val_accuracy: 0.5648\n",
      "Epoch 411/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5547 - accuracy: 0.8085 - val_loss: 1.7064 - val_accuracy: 0.5648\n",
      "Epoch 412/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5602 - accuracy: 0.8165 - val_loss: 1.7037 - val_accuracy: 0.5648\n",
      "Epoch 413/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5831 - accuracy: 0.8026 - val_loss: 1.7101 - val_accuracy: 0.5556\n",
      "Epoch 414/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5805 - accuracy: 0.7976 - val_loss: 1.7054 - val_accuracy: 0.5602\n",
      "Epoch 415/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5658 - accuracy: 0.8056 - val_loss: 1.7032 - val_accuracy: 0.5579\n",
      "Epoch 416/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5415 - accuracy: 0.8234 - val_loss: 1.7055 - val_accuracy: 0.5625\n",
      "Epoch 417/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5678 - accuracy: 0.7956 - val_loss: 1.7066 - val_accuracy: 0.5579\n",
      "Epoch 418/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5547 - accuracy: 0.8185 - val_loss: 1.7044 - val_accuracy: 0.5625\n",
      "Epoch 419/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5583 - accuracy: 0.8105 - val_loss: 1.7038 - val_accuracy: 0.5671\n",
      "Epoch 420/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5811 - accuracy: 0.8036 - val_loss: 1.7109 - val_accuracy: 0.5694\n",
      "Epoch 421/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5575 - accuracy: 0.8006 - val_loss: 1.7103 - val_accuracy: 0.5648\n",
      "Epoch 422/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5504 - accuracy: 0.8075 - val_loss: 1.7073 - val_accuracy: 0.5648\n",
      "Epoch 423/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5697 - accuracy: 0.7986 - val_loss: 1.7032 - val_accuracy: 0.5602\n",
      "Epoch 424/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5526 - accuracy: 0.8125 - val_loss: 1.7038 - val_accuracy: 0.5602\n",
      "Epoch 425/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5599 - accuracy: 0.8085 - val_loss: 1.7065 - val_accuracy: 0.5648\n",
      "Epoch 426/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5560 - accuracy: 0.7976 - val_loss: 1.7057 - val_accuracy: 0.5625\n",
      "Epoch 427/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5688 - accuracy: 0.8065 - val_loss: 1.7059 - val_accuracy: 0.5648\n",
      "Epoch 428/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5590 - accuracy: 0.8085 - val_loss: 1.7043 - val_accuracy: 0.5625\n",
      "Epoch 429/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5728 - accuracy: 0.8105 - val_loss: 1.7038 - val_accuracy: 0.5625\n",
      "Epoch 430/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5546 - accuracy: 0.7946 - val_loss: 1.6983 - val_accuracy: 0.5602\n",
      "Epoch 431/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5356 - accuracy: 0.8244 - val_loss: 1.7003 - val_accuracy: 0.5648\n",
      "Epoch 432/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5551 - accuracy: 0.8036 - val_loss: 1.6963 - val_accuracy: 0.5602\n",
      "Epoch 433/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5864 - accuracy: 0.7798 - val_loss: 1.6992 - val_accuracy: 0.5602\n",
      "Epoch 434/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5440 - accuracy: 0.8185 - val_loss: 1.7047 - val_accuracy: 0.5602\n",
      "Epoch 435/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5429 - accuracy: 0.8075 - val_loss: 1.7091 - val_accuracy: 0.5579\n",
      "Epoch 436/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5474 - accuracy: 0.8194 - val_loss: 1.7090 - val_accuracy: 0.5648\n",
      "Epoch 437/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5718 - accuracy: 0.8006 - val_loss: 1.7052 - val_accuracy: 0.5648\n",
      "Epoch 438/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5592 - accuracy: 0.8095 - val_loss: 1.7018 - val_accuracy: 0.5648\n",
      "Epoch 439/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5505 - accuracy: 0.8095 - val_loss: 1.7051 - val_accuracy: 0.5671\n",
      "Epoch 440/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5836 - accuracy: 0.7917 - val_loss: 1.7025 - val_accuracy: 0.5648\n",
      "Epoch 441/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5631 - accuracy: 0.8105 - val_loss: 1.7013 - val_accuracy: 0.5648\n",
      "Epoch 442/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.8214 - val_loss: 1.7017 - val_accuracy: 0.5648\n",
      "Epoch 443/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5489 - accuracy: 0.8135 - val_loss: 1.6991 - val_accuracy: 0.5579\n",
      "Epoch 444/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5659 - accuracy: 0.8065 - val_loss: 1.7060 - val_accuracy: 0.5602\n",
      "Epoch 445/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5364 - accuracy: 0.8254 - val_loss: 1.7023 - val_accuracy: 0.5625\n",
      "Epoch 446/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5529 - accuracy: 0.8075 - val_loss: 1.7037 - val_accuracy: 0.5625\n",
      "Epoch 447/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5490 - accuracy: 0.8185 - val_loss: 1.6971 - val_accuracy: 0.5602\n",
      "Epoch 448/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5451 - accuracy: 0.8165 - val_loss: 1.6983 - val_accuracy: 0.5602\n",
      "Epoch 449/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5319 - accuracy: 0.8284 - val_loss: 1.6963 - val_accuracy: 0.5648\n",
      "Epoch 450/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5533 - accuracy: 0.8155 - val_loss: 1.6963 - val_accuracy: 0.5625\n",
      "Epoch 451/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5392 - accuracy: 0.8115 - val_loss: 1.6960 - val_accuracy: 0.5648\n",
      "Epoch 452/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5500 - accuracy: 0.8115 - val_loss: 1.7020 - val_accuracy: 0.5556\n",
      "Epoch 453/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.8284 - val_loss: 1.6985 - val_accuracy: 0.5625\n",
      "Epoch 454/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5351 - accuracy: 0.8204 - val_loss: 1.6993 - val_accuracy: 0.5602\n",
      "Epoch 455/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5335 - accuracy: 0.8115 - val_loss: 1.7031 - val_accuracy: 0.5648\n",
      "Epoch 456/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5290 - accuracy: 0.8145 - val_loss: 1.7080 - val_accuracy: 0.5671\n",
      "Epoch 457/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5558 - accuracy: 0.8125 - val_loss: 1.7090 - val_accuracy: 0.5648\n",
      "Epoch 458/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5741 - accuracy: 0.8056 - val_loss: 1.7020 - val_accuracy: 0.5648\n",
      "Epoch 459/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.8155 - val_loss: 1.6961 - val_accuracy: 0.5556\n",
      "Epoch 460/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5228 - accuracy: 0.8304 - val_loss: 1.7013 - val_accuracy: 0.5625\n",
      "Epoch 461/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5541 - accuracy: 0.8254 - val_loss: 1.7041 - val_accuracy: 0.5625\n",
      "Epoch 462/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5385 - accuracy: 0.8175 - val_loss: 1.7026 - val_accuracy: 0.5602\n",
      "Epoch 463/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5505 - accuracy: 0.8056 - val_loss: 1.7005 - val_accuracy: 0.5671\n",
      "Epoch 464/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5731 - accuracy: 0.8155 - val_loss: 1.6999 - val_accuracy: 0.5648\n",
      "Epoch 465/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5745 - accuracy: 0.8095 - val_loss: 1.6977 - val_accuracy: 0.5694\n",
      "Epoch 466/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5478 - accuracy: 0.8105 - val_loss: 1.6978 - val_accuracy: 0.5648\n",
      "Epoch 467/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5518 - accuracy: 0.8165 - val_loss: 1.6979 - val_accuracy: 0.5625\n",
      "Epoch 468/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.8165 - val_loss: 1.6969 - val_accuracy: 0.5625\n",
      "Epoch 469/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5633 - accuracy: 0.8095 - val_loss: 1.6949 - val_accuracy: 0.5648\n",
      "Epoch 470/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5416 - accuracy: 0.8244 - val_loss: 1.7000 - val_accuracy: 0.5602\n",
      "Epoch 471/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5581 - accuracy: 0.8105 - val_loss: 1.6962 - val_accuracy: 0.5579\n",
      "Epoch 472/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5424 - accuracy: 0.8095 - val_loss: 1.6992 - val_accuracy: 0.5648\n",
      "Epoch 473/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5546 - accuracy: 0.8264 - val_loss: 1.7015 - val_accuracy: 0.5602\n",
      "Epoch 474/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5576 - accuracy: 0.8234 - val_loss: 1.6995 - val_accuracy: 0.5579\n",
      "Epoch 475/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5568 - accuracy: 0.8204 - val_loss: 1.6948 - val_accuracy: 0.5625\n",
      "Epoch 476/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.8194 - val_loss: 1.6955 - val_accuracy: 0.5602\n",
      "Epoch 477/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5240 - accuracy: 0.8085 - val_loss: 1.6957 - val_accuracy: 0.5579\n",
      "Epoch 478/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5484 - accuracy: 0.8115 - val_loss: 1.6974 - val_accuracy: 0.5671\n",
      "Epoch 479/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5472 - accuracy: 0.8135 - val_loss: 1.6997 - val_accuracy: 0.5671\n",
      "Epoch 480/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5552 - accuracy: 0.8175 - val_loss: 1.7013 - val_accuracy: 0.5648\n",
      "Epoch 481/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5410 - accuracy: 0.8194 - val_loss: 1.7000 - val_accuracy: 0.5648\n",
      "Epoch 482/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5570 - accuracy: 0.8155 - val_loss: 1.7047 - val_accuracy: 0.5648\n",
      "Epoch 483/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5401 - accuracy: 0.8244 - val_loss: 1.7066 - val_accuracy: 0.5602\n",
      "Epoch 484/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5234 - accuracy: 0.8105 - val_loss: 1.7108 - val_accuracy: 0.5602\n",
      "Epoch 485/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.8046 - val_loss: 1.7053 - val_accuracy: 0.5602\n",
      "Epoch 486/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.8155 - val_loss: 1.7064 - val_accuracy: 0.5602\n",
      "Epoch 487/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5602 - accuracy: 0.8085 - val_loss: 1.7042 - val_accuracy: 0.5602\n",
      "Epoch 488/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5367 - accuracy: 0.8194 - val_loss: 1.7022 - val_accuracy: 0.5671\n",
      "Epoch 489/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5465 - accuracy: 0.8065 - val_loss: 1.7039 - val_accuracy: 0.5625\n",
      "Epoch 490/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5469 - accuracy: 0.8135 - val_loss: 1.7027 - val_accuracy: 0.5625\n",
      "Epoch 491/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5475 - accuracy: 0.8075 - val_loss: 1.7061 - val_accuracy: 0.5671\n",
      "Epoch 492/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5444 - accuracy: 0.8204 - val_loss: 1.7104 - val_accuracy: 0.5671\n",
      "Epoch 493/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5564 - accuracy: 0.8026 - val_loss: 1.7100 - val_accuracy: 0.5671\n",
      "Epoch 494/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5251 - accuracy: 0.8343 - val_loss: 1.7074 - val_accuracy: 0.5648\n",
      "Epoch 495/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5462 - accuracy: 0.8105 - val_loss: 1.7062 - val_accuracy: 0.5602\n",
      "Epoch 496/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.8175 - val_loss: 1.7080 - val_accuracy: 0.5625\n",
      "Epoch 497/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5591 - accuracy: 0.8065 - val_loss: 1.7096 - val_accuracy: 0.5648\n",
      "Epoch 498/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5320 - accuracy: 0.8234 - val_loss: 1.7084 - val_accuracy: 0.5648\n",
      "Epoch 499/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5353 - accuracy: 0.8095 - val_loss: 1.7043 - val_accuracy: 0.5648\n",
      "Epoch 500/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5474 - accuracy: 0.8085 - val_loss: 1.7006 - val_accuracy: 0.5625\n",
      "Epoch 501/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.8145 - val_loss: 1.7009 - val_accuracy: 0.5602\n",
      "Epoch 502/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5588 - accuracy: 0.8165 - val_loss: 1.7012 - val_accuracy: 0.5602\n",
      "Epoch 503/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.8234 - val_loss: 1.7025 - val_accuracy: 0.5579\n",
      "Epoch 504/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5224 - accuracy: 0.8224 - val_loss: 1.7053 - val_accuracy: 0.5556\n",
      "Epoch 505/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5346 - accuracy: 0.8194 - val_loss: 1.7024 - val_accuracy: 0.5602\n",
      "Epoch 506/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5347 - accuracy: 0.8105 - val_loss: 1.7018 - val_accuracy: 0.5648\n",
      "Epoch 507/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5232 - accuracy: 0.8224 - val_loss: 1.7077 - val_accuracy: 0.5602\n",
      "Epoch 508/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5334 - accuracy: 0.8214 - val_loss: 1.7055 - val_accuracy: 0.5532\n",
      "Epoch 509/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5376 - accuracy: 0.8155 - val_loss: 1.7054 - val_accuracy: 0.5579\n",
      "Epoch 510/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5355 - accuracy: 0.8214 - val_loss: 1.7066 - val_accuracy: 0.5602\n",
      "Epoch 511/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5403 - accuracy: 0.7986 - val_loss: 1.7109 - val_accuracy: 0.5625\n",
      "Epoch 512/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5388 - accuracy: 0.8056 - val_loss: 1.7136 - val_accuracy: 0.5556\n",
      "Epoch 513/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5318 - accuracy: 0.8204 - val_loss: 1.7119 - val_accuracy: 0.5579\n",
      "Epoch 514/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5354 - accuracy: 0.8165 - val_loss: 1.7128 - val_accuracy: 0.5648\n",
      "Epoch 515/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.8185 - val_loss: 1.7097 - val_accuracy: 0.5625\n",
      "Epoch 516/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5313 - accuracy: 0.8204 - val_loss: 1.7106 - val_accuracy: 0.5602\n",
      "Epoch 517/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5199 - accuracy: 0.8294 - val_loss: 1.7112 - val_accuracy: 0.5625\n",
      "Epoch 518/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5105 - accuracy: 0.8403 - val_loss: 1.7098 - val_accuracy: 0.5625\n",
      "Epoch 519/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5269 - accuracy: 0.8175 - val_loss: 1.7125 - val_accuracy: 0.5648\n",
      "Epoch 520/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5331 - accuracy: 0.8085 - val_loss: 1.7146 - val_accuracy: 0.5579\n",
      "Epoch 521/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5522 - accuracy: 0.8145 - val_loss: 1.7138 - val_accuracy: 0.5602\n",
      "Epoch 522/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5332 - accuracy: 0.8125 - val_loss: 1.7131 - val_accuracy: 0.5579\n",
      "Epoch 523/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5182 - accuracy: 0.8254 - val_loss: 1.7068 - val_accuracy: 0.5579\n",
      "Epoch 524/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5241 - accuracy: 0.8304 - val_loss: 1.7105 - val_accuracy: 0.5579\n",
      "Epoch 525/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5414 - accuracy: 0.8036 - val_loss: 1.7052 - val_accuracy: 0.5671\n",
      "Epoch 526/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5472 - accuracy: 0.8085 - val_loss: 1.7067 - val_accuracy: 0.5602\n",
      "Epoch 527/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5339 - accuracy: 0.8125 - val_loss: 1.7082 - val_accuracy: 0.5648\n",
      "Epoch 528/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5336 - accuracy: 0.8264 - val_loss: 1.7095 - val_accuracy: 0.5579\n",
      "Epoch 529/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5225 - accuracy: 0.8165 - val_loss: 1.7113 - val_accuracy: 0.5602\n",
      "Epoch 530/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5323 - accuracy: 0.8214 - val_loss: 1.7160 - val_accuracy: 0.5625\n",
      "Epoch 531/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5575 - accuracy: 0.8155 - val_loss: 1.7150 - val_accuracy: 0.5602\n",
      "Epoch 532/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5686 - accuracy: 0.8105 - val_loss: 1.7098 - val_accuracy: 0.5602\n",
      "Epoch 533/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5321 - accuracy: 0.8244 - val_loss: 1.7087 - val_accuracy: 0.5625\n",
      "Epoch 534/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5239 - accuracy: 0.8323 - val_loss: 1.7112 - val_accuracy: 0.5648\n",
      "Epoch 535/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5187 - accuracy: 0.8294 - val_loss: 1.7160 - val_accuracy: 0.5625\n",
      "Epoch 536/1000\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: 0.5496 - accuracy: 0.8155 - val_loss: 1.7160 - val_accuracy: 0.5648\n",
      "Epoch 537/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5051 - accuracy: 0.8353 - val_loss: 1.7156 - val_accuracy: 0.5625\n",
      "Epoch 538/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5421 - accuracy: 0.8214 - val_loss: 1.7146 - val_accuracy: 0.5648\n",
      "Epoch 539/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5123 - accuracy: 0.8264 - val_loss: 1.7188 - val_accuracy: 0.5625\n",
      "Epoch 540/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5349 - accuracy: 0.8274 - val_loss: 1.7198 - val_accuracy: 0.5625\n",
      "Epoch 541/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5302 - accuracy: 0.8115 - val_loss: 1.7192 - val_accuracy: 0.5579\n",
      "Epoch 542/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5459 - accuracy: 0.8194 - val_loss: 1.7211 - val_accuracy: 0.5579\n",
      "Epoch 543/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5183 - accuracy: 0.8244 - val_loss: 1.7186 - val_accuracy: 0.5579\n",
      "Epoch 544/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.8135 - val_loss: 1.7154 - val_accuracy: 0.5602\n",
      "Epoch 545/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5285 - accuracy: 0.8234 - val_loss: 1.7206 - val_accuracy: 0.5602\n",
      "Epoch 546/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5433 - accuracy: 0.8056 - val_loss: 1.7202 - val_accuracy: 0.5625\n",
      "Epoch 547/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5343 - accuracy: 0.8056 - val_loss: 1.7171 - val_accuracy: 0.5556\n",
      "Epoch 548/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5102 - accuracy: 0.8145 - val_loss: 1.7157 - val_accuracy: 0.5602\n",
      "Epoch 549/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5294 - accuracy: 0.8264 - val_loss: 1.7193 - val_accuracy: 0.5625\n",
      "Epoch 550/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5651 - accuracy: 0.8185 - val_loss: 1.7208 - val_accuracy: 0.5625\n",
      "Epoch 551/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5376 - accuracy: 0.8155 - val_loss: 1.7210 - val_accuracy: 0.5602\n",
      "Epoch 552/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5558 - accuracy: 0.8185 - val_loss: 1.7202 - val_accuracy: 0.5602\n",
      "Epoch 553/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5299 - accuracy: 0.8026 - val_loss: 1.7201 - val_accuracy: 0.5579\n",
      "Epoch 554/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5182 - accuracy: 0.8224 - val_loss: 1.7171 - val_accuracy: 0.5625\n",
      "Epoch 555/1000\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: 0.5207 - accuracy: 0.8234 - val_loss: 1.7190 - val_accuracy: 0.5602\n",
      "Epoch 556/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5171 - accuracy: 0.8185 - val_loss: 1.7144 - val_accuracy: 0.5625\n",
      "Epoch 557/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5381 - accuracy: 0.8214 - val_loss: 1.7097 - val_accuracy: 0.5579\n",
      "Epoch 558/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5089 - accuracy: 0.8323 - val_loss: 1.7113 - val_accuracy: 0.5602\n",
      "Epoch 559/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5324 - accuracy: 0.8095 - val_loss: 1.7147 - val_accuracy: 0.5579\n",
      "Epoch 560/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5312 - accuracy: 0.8234 - val_loss: 1.7154 - val_accuracy: 0.5648\n",
      "Epoch 561/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5403 - accuracy: 0.8115 - val_loss: 1.7182 - val_accuracy: 0.5602\n",
      "Epoch 562/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5393 - accuracy: 0.8234 - val_loss: 1.7164 - val_accuracy: 0.5648\n",
      "Epoch 563/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5150 - accuracy: 0.8274 - val_loss: 1.7161 - val_accuracy: 0.5648\n",
      "Epoch 564/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5178 - accuracy: 0.8244 - val_loss: 1.7159 - val_accuracy: 0.5694\n",
      "Epoch 565/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5210 - accuracy: 0.8115 - val_loss: 1.7169 - val_accuracy: 0.5648\n",
      "Epoch 566/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5186 - accuracy: 0.8185 - val_loss: 1.7172 - val_accuracy: 0.5602\n",
      "Epoch 567/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5207 - accuracy: 0.8313 - val_loss: 1.7187 - val_accuracy: 0.5648\n",
      "Epoch 568/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5289 - accuracy: 0.8333 - val_loss: 1.7197 - val_accuracy: 0.5648\n",
      "Epoch 569/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4990 - accuracy: 0.8442 - val_loss: 1.7218 - val_accuracy: 0.5625\n",
      "Epoch 570/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5065 - accuracy: 0.8323 - val_loss: 1.7214 - val_accuracy: 0.5625\n",
      "Epoch 571/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5316 - accuracy: 0.8185 - val_loss: 1.7202 - val_accuracy: 0.5602\n",
      "Epoch 572/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5248 - accuracy: 0.8175 - val_loss: 1.7206 - val_accuracy: 0.5602\n",
      "Epoch 573/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5118 - accuracy: 0.8323 - val_loss: 1.7192 - val_accuracy: 0.5579\n",
      "Epoch 574/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4986 - accuracy: 0.8323 - val_loss: 1.7204 - val_accuracy: 0.5556\n",
      "Epoch 575/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5159 - accuracy: 0.8214 - val_loss: 1.7193 - val_accuracy: 0.5602\n",
      "Epoch 576/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5481 - accuracy: 0.8155 - val_loss: 1.7220 - val_accuracy: 0.5648\n",
      "Epoch 577/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.8264 - val_loss: 1.7196 - val_accuracy: 0.5579\n",
      "Epoch 578/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5333 - accuracy: 0.8234 - val_loss: 1.7179 - val_accuracy: 0.5532\n",
      "Epoch 579/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5114 - accuracy: 0.8185 - val_loss: 1.7163 - val_accuracy: 0.5602\n",
      "Epoch 580/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4914 - accuracy: 0.8403 - val_loss: 1.7198 - val_accuracy: 0.5579\n",
      "Epoch 581/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5226 - accuracy: 0.8304 - val_loss: 1.7233 - val_accuracy: 0.5532\n",
      "Epoch 582/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5050 - accuracy: 0.8145 - val_loss: 1.7212 - val_accuracy: 0.5625\n",
      "Epoch 583/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5225 - accuracy: 0.8353 - val_loss: 1.7206 - val_accuracy: 0.5602\n",
      "Epoch 584/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5114 - accuracy: 0.8185 - val_loss: 1.7182 - val_accuracy: 0.5625\n",
      "Epoch 585/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5286 - accuracy: 0.8185 - val_loss: 1.7191 - val_accuracy: 0.5602\n",
      "Epoch 586/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5194 - accuracy: 0.8234 - val_loss: 1.7175 - val_accuracy: 0.5532\n",
      "Epoch 587/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5035 - accuracy: 0.8304 - val_loss: 1.7205 - val_accuracy: 0.5532\n",
      "Epoch 588/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5197 - accuracy: 0.8284 - val_loss: 1.7177 - val_accuracy: 0.5579\n",
      "Epoch 589/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5399 - accuracy: 0.8165 - val_loss: 1.7162 - val_accuracy: 0.5532\n",
      "Epoch 590/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5337 - accuracy: 0.8234 - val_loss: 1.7193 - val_accuracy: 0.5602\n",
      "Epoch 591/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5086 - accuracy: 0.8294 - val_loss: 1.7200 - val_accuracy: 0.5579\n",
      "Epoch 592/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5169 - accuracy: 0.8204 - val_loss: 1.7209 - val_accuracy: 0.5602\n",
      "Epoch 593/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5205 - accuracy: 0.8125 - val_loss: 1.7223 - val_accuracy: 0.5648\n",
      "Epoch 594/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4990 - accuracy: 0.8442 - val_loss: 1.7177 - val_accuracy: 0.5625\n",
      "Epoch 595/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5180 - accuracy: 0.8264 - val_loss: 1.7226 - val_accuracy: 0.5602\n",
      "Epoch 596/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5108 - accuracy: 0.8274 - val_loss: 1.7205 - val_accuracy: 0.5602\n",
      "Epoch 597/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5052 - accuracy: 0.8234 - val_loss: 1.7204 - val_accuracy: 0.5625\n",
      "Epoch 598/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5001 - accuracy: 0.8413 - val_loss: 1.7258 - val_accuracy: 0.5648\n",
      "Epoch 599/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5052 - accuracy: 0.8353 - val_loss: 1.7226 - val_accuracy: 0.5602\n",
      "Epoch 600/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5062 - accuracy: 0.8333 - val_loss: 1.7204 - val_accuracy: 0.5602\n",
      "Epoch 601/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4951 - accuracy: 0.8353 - val_loss: 1.7172 - val_accuracy: 0.5648\n",
      "Epoch 602/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5010 - accuracy: 0.8363 - val_loss: 1.7200 - val_accuracy: 0.5648\n",
      "Epoch 603/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4977 - accuracy: 0.8333 - val_loss: 1.7197 - val_accuracy: 0.5625\n",
      "Epoch 604/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4994 - accuracy: 0.8373 - val_loss: 1.7202 - val_accuracy: 0.5579\n",
      "Epoch 605/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5068 - accuracy: 0.8264 - val_loss: 1.7192 - val_accuracy: 0.5602\n",
      "Epoch 606/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5002 - accuracy: 0.8254 - val_loss: 1.7222 - val_accuracy: 0.5579\n",
      "Epoch 607/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4984 - accuracy: 0.8323 - val_loss: 1.7224 - val_accuracy: 0.5602\n",
      "Epoch 608/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5509 - accuracy: 0.8194 - val_loss: 1.7203 - val_accuracy: 0.5579\n",
      "Epoch 609/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4998 - accuracy: 0.8234 - val_loss: 1.7211 - val_accuracy: 0.5579\n",
      "Epoch 610/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.8155 - val_loss: 1.7194 - val_accuracy: 0.5602\n",
      "Epoch 611/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4852 - accuracy: 0.8373 - val_loss: 1.7229 - val_accuracy: 0.5556\n",
      "Epoch 612/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4980 - accuracy: 0.8353 - val_loss: 1.7232 - val_accuracy: 0.5556\n",
      "Epoch 613/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5054 - accuracy: 0.8333 - val_loss: 1.7201 - val_accuracy: 0.5556\n",
      "Epoch 614/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5278 - accuracy: 0.8036 - val_loss: 1.7241 - val_accuracy: 0.5579\n",
      "Epoch 615/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5055 - accuracy: 0.8244 - val_loss: 1.7205 - val_accuracy: 0.5556\n",
      "Epoch 616/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5190 - accuracy: 0.8254 - val_loss: 1.7236 - val_accuracy: 0.5532\n",
      "Epoch 617/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4900 - accuracy: 0.8373 - val_loss: 1.7246 - val_accuracy: 0.5556\n",
      "Epoch 618/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5252 - accuracy: 0.8274 - val_loss: 1.7210 - val_accuracy: 0.5556\n",
      "Epoch 619/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5040 - accuracy: 0.8284 - val_loss: 1.7239 - val_accuracy: 0.5579\n",
      "Epoch 620/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5103 - accuracy: 0.8254 - val_loss: 1.7251 - val_accuracy: 0.5579\n",
      "Epoch 621/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5098 - accuracy: 0.8304 - val_loss: 1.7260 - val_accuracy: 0.5625\n",
      "Epoch 622/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5191 - accuracy: 0.8264 - val_loss: 1.7215 - val_accuracy: 0.5625\n",
      "Epoch 623/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5236 - accuracy: 0.8204 - val_loss: 1.7197 - val_accuracy: 0.5579\n",
      "Epoch 624/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4855 - accuracy: 0.8383 - val_loss: 1.7202 - val_accuracy: 0.5602\n",
      "Epoch 625/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5184 - accuracy: 0.8274 - val_loss: 1.7200 - val_accuracy: 0.5602\n",
      "Epoch 626/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5379 - accuracy: 0.8284 - val_loss: 1.7200 - val_accuracy: 0.5556\n",
      "Epoch 627/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4915 - accuracy: 0.8343 - val_loss: 1.7223 - val_accuracy: 0.5579\n",
      "Epoch 628/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5036 - accuracy: 0.8224 - val_loss: 1.7240 - val_accuracy: 0.5602\n",
      "Epoch 629/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5118 - accuracy: 0.8294 - val_loss: 1.7241 - val_accuracy: 0.5556\n",
      "Epoch 630/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4892 - accuracy: 0.8423 - val_loss: 1.7248 - val_accuracy: 0.5579\n",
      "Epoch 631/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5104 - accuracy: 0.8185 - val_loss: 1.7215 - val_accuracy: 0.5556\n",
      "Epoch 632/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5017 - accuracy: 0.8353 - val_loss: 1.7203 - val_accuracy: 0.5532\n",
      "Epoch 633/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.8165 - val_loss: 1.7224 - val_accuracy: 0.5579\n",
      "Epoch 634/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5138 - accuracy: 0.8403 - val_loss: 1.7297 - val_accuracy: 0.5532\n",
      "Epoch 635/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4879 - accuracy: 0.8294 - val_loss: 1.7283 - val_accuracy: 0.5579\n",
      "Epoch 636/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5335 - accuracy: 0.8343 - val_loss: 1.7272 - val_accuracy: 0.5579\n",
      "Epoch 637/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5241 - accuracy: 0.8363 - val_loss: 1.7307 - val_accuracy: 0.5509\n",
      "Epoch 638/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5265 - accuracy: 0.8214 - val_loss: 1.7287 - val_accuracy: 0.5556\n",
      "Epoch 639/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5002 - accuracy: 0.8185 - val_loss: 1.7269 - val_accuracy: 0.5579\n",
      "Epoch 640/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5123 - accuracy: 0.8284 - val_loss: 1.7298 - val_accuracy: 0.5532\n",
      "Epoch 641/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4920 - accuracy: 0.8254 - val_loss: 1.7287 - val_accuracy: 0.5556\n",
      "Epoch 642/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4979 - accuracy: 0.8313 - val_loss: 1.7297 - val_accuracy: 0.5556\n",
      "Epoch 643/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5113 - accuracy: 0.8294 - val_loss: 1.7322 - val_accuracy: 0.5556\n",
      "Epoch 644/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5160 - accuracy: 0.8135 - val_loss: 1.7283 - val_accuracy: 0.5579\n",
      "Epoch 645/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5193 - accuracy: 0.8323 - val_loss: 1.7282 - val_accuracy: 0.5579\n",
      "Epoch 646/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5042 - accuracy: 0.8363 - val_loss: 1.7265 - val_accuracy: 0.5579\n",
      "Epoch 647/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4939 - accuracy: 0.8313 - val_loss: 1.7310 - val_accuracy: 0.5625\n",
      "Epoch 648/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5229 - accuracy: 0.8274 - val_loss: 1.7287 - val_accuracy: 0.5625\n",
      "Epoch 649/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5041 - accuracy: 0.8284 - val_loss: 1.7246 - val_accuracy: 0.5579\n",
      "Epoch 650/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.5059 - accuracy: 0.8353 - val_loss: 1.7261 - val_accuracy: 0.5648\n",
      "Epoch 651/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5280 - accuracy: 0.8274 - val_loss: 1.7215 - val_accuracy: 0.5625\n",
      "Epoch 652/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5074 - accuracy: 0.8442 - val_loss: 1.7249 - val_accuracy: 0.5602\n",
      "Epoch 653/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5010 - accuracy: 0.8284 - val_loss: 1.7275 - val_accuracy: 0.5602\n",
      "Epoch 654/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4910 - accuracy: 0.8433 - val_loss: 1.7283 - val_accuracy: 0.5532\n",
      "Epoch 655/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5123 - accuracy: 0.8323 - val_loss: 1.7307 - val_accuracy: 0.5556\n",
      "Epoch 656/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5489 - accuracy: 0.8125 - val_loss: 1.7245 - val_accuracy: 0.5602\n",
      "Epoch 657/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5162 - accuracy: 0.8214 - val_loss: 1.7286 - val_accuracy: 0.5579\n",
      "Epoch 658/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5134 - accuracy: 0.8274 - val_loss: 1.7297 - val_accuracy: 0.5556\n",
      "Epoch 659/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4957 - accuracy: 0.8294 - val_loss: 1.7287 - val_accuracy: 0.5532\n",
      "Epoch 660/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5177 - accuracy: 0.8304 - val_loss: 1.7282 - val_accuracy: 0.5532\n",
      "Epoch 661/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5152 - accuracy: 0.8363 - val_loss: 1.7282 - val_accuracy: 0.5509\n",
      "Epoch 662/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4944 - accuracy: 0.8313 - val_loss: 1.7266 - val_accuracy: 0.5579\n",
      "Epoch 663/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4939 - accuracy: 0.8333 - val_loss: 1.7270 - val_accuracy: 0.5556\n",
      "Epoch 664/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5210 - accuracy: 0.8274 - val_loss: 1.7306 - val_accuracy: 0.5532\n",
      "Epoch 665/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4861 - accuracy: 0.8452 - val_loss: 1.7291 - val_accuracy: 0.5509\n",
      "Epoch 666/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5069 - accuracy: 0.8274 - val_loss: 1.7255 - val_accuracy: 0.5509\n",
      "Epoch 667/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4940 - accuracy: 0.8333 - val_loss: 1.7252 - val_accuracy: 0.5532\n",
      "Epoch 668/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5260 - accuracy: 0.8284 - val_loss: 1.7270 - val_accuracy: 0.5509\n",
      "Epoch 669/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4927 - accuracy: 0.8244 - val_loss: 1.7302 - val_accuracy: 0.5532\n",
      "Epoch 670/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.8016 - val_loss: 1.7314 - val_accuracy: 0.5532\n",
      "Epoch 671/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5231 - accuracy: 0.8274 - val_loss: 1.7291 - val_accuracy: 0.5509\n",
      "Epoch 672/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4966 - accuracy: 0.8323 - val_loss: 1.7253 - val_accuracy: 0.5532\n",
      "Epoch 673/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5019 - accuracy: 0.8393 - val_loss: 1.7252 - val_accuracy: 0.5579\n",
      "Epoch 674/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4681 - accuracy: 0.8433 - val_loss: 1.7267 - val_accuracy: 0.5532\n",
      "Epoch 675/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4924 - accuracy: 0.8413 - val_loss: 1.7290 - val_accuracy: 0.5556\n",
      "Epoch 676/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4747 - accuracy: 0.8403 - val_loss: 1.7281 - val_accuracy: 0.5532\n",
      "Epoch 677/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4969 - accuracy: 0.8373 - val_loss: 1.7300 - val_accuracy: 0.5579\n",
      "Epoch 678/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5008 - accuracy: 0.8294 - val_loss: 1.7282 - val_accuracy: 0.5509\n",
      "Epoch 679/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5063 - accuracy: 0.8224 - val_loss: 1.7281 - val_accuracy: 0.5579\n",
      "Epoch 680/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5211 - accuracy: 0.8373 - val_loss: 1.7292 - val_accuracy: 0.5556\n",
      "Epoch 681/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4978 - accuracy: 0.8224 - val_loss: 1.7301 - val_accuracy: 0.5532\n",
      "Epoch 682/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4842 - accuracy: 0.8512 - val_loss: 1.7290 - val_accuracy: 0.5532\n",
      "Epoch 683/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4941 - accuracy: 0.8294 - val_loss: 1.7294 - val_accuracy: 0.5602\n",
      "Epoch 684/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4778 - accuracy: 0.8353 - val_loss: 1.7326 - val_accuracy: 0.5602\n",
      "Epoch 685/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4754 - accuracy: 0.8413 - val_loss: 1.7354 - val_accuracy: 0.5579\n",
      "Epoch 686/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5076 - accuracy: 0.8274 - val_loss: 1.7341 - val_accuracy: 0.5509\n",
      "Epoch 687/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4858 - accuracy: 0.8403 - val_loss: 1.7314 - val_accuracy: 0.5532\n",
      "Epoch 688/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4886 - accuracy: 0.8452 - val_loss: 1.7320 - val_accuracy: 0.5532\n",
      "Epoch 689/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5010 - accuracy: 0.8343 - val_loss: 1.7332 - val_accuracy: 0.5579\n",
      "Epoch 690/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4773 - accuracy: 0.8254 - val_loss: 1.7329 - val_accuracy: 0.5625\n",
      "Epoch 691/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4826 - accuracy: 0.8413 - val_loss: 1.7302 - val_accuracy: 0.5556\n",
      "Epoch 692/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5049 - accuracy: 0.8244 - val_loss: 1.7299 - val_accuracy: 0.5556\n",
      "Epoch 693/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4842 - accuracy: 0.8442 - val_loss: 1.7289 - val_accuracy: 0.5579\n",
      "Epoch 694/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4877 - accuracy: 0.8433 - val_loss: 1.7273 - val_accuracy: 0.5556\n",
      "Epoch 695/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4946 - accuracy: 0.8274 - val_loss: 1.7297 - val_accuracy: 0.5509\n",
      "Epoch 696/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5035 - accuracy: 0.8284 - val_loss: 1.7300 - val_accuracy: 0.5602\n",
      "Epoch 697/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4958 - accuracy: 0.8333 - val_loss: 1.7259 - val_accuracy: 0.5556\n",
      "Epoch 698/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5304 - accuracy: 0.8363 - val_loss: 1.7299 - val_accuracy: 0.5602\n",
      "Epoch 699/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5036 - accuracy: 0.8433 - val_loss: 1.7280 - val_accuracy: 0.5556\n",
      "Epoch 700/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4778 - accuracy: 0.8433 - val_loss: 1.7319 - val_accuracy: 0.5509\n",
      "Epoch 701/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4817 - accuracy: 0.8403 - val_loss: 1.7324 - val_accuracy: 0.5556\n",
      "Epoch 702/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5014 - accuracy: 0.8333 - val_loss: 1.7338 - val_accuracy: 0.5532\n",
      "Epoch 703/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5111 - accuracy: 0.8313 - val_loss: 1.7358 - val_accuracy: 0.5579\n",
      "Epoch 704/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5119 - accuracy: 0.8115 - val_loss: 1.7302 - val_accuracy: 0.5556\n",
      "Epoch 705/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5010 - accuracy: 0.8204 - val_loss: 1.7339 - val_accuracy: 0.5602\n",
      "Epoch 706/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4806 - accuracy: 0.8343 - val_loss: 1.7323 - val_accuracy: 0.5556\n",
      "Epoch 707/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4940 - accuracy: 0.8353 - val_loss: 1.7309 - val_accuracy: 0.5556\n",
      "Epoch 708/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4945 - accuracy: 0.8373 - val_loss: 1.7338 - val_accuracy: 0.5579\n",
      "Epoch 709/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4886 - accuracy: 0.8313 - val_loss: 1.7333 - val_accuracy: 0.5602\n",
      "Epoch 710/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4969 - accuracy: 0.8433 - val_loss: 1.7319 - val_accuracy: 0.5556\n",
      "Epoch 711/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4782 - accuracy: 0.8363 - val_loss: 1.7354 - val_accuracy: 0.5579\n",
      "Epoch 712/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4945 - accuracy: 0.8373 - val_loss: 1.7331 - val_accuracy: 0.5509\n",
      "Epoch 713/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4904 - accuracy: 0.8403 - val_loss: 1.7329 - val_accuracy: 0.5486\n",
      "Epoch 714/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5209 - accuracy: 0.8383 - val_loss: 1.7317 - val_accuracy: 0.5509\n",
      "Epoch 715/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4914 - accuracy: 0.8363 - val_loss: 1.7351 - val_accuracy: 0.5556\n",
      "Epoch 716/1000\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: 0.4870 - accuracy: 0.8313 - val_loss: 1.7373 - val_accuracy: 0.5532\n",
      "Epoch 717/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4877 - accuracy: 0.8313 - val_loss: 1.7342 - val_accuracy: 0.5509\n",
      "Epoch 718/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4854 - accuracy: 0.8304 - val_loss: 1.7333 - val_accuracy: 0.5556\n",
      "Epoch 719/1000\n",
      "1008/1008 [==============================] - 4s 4ms/step - loss: 0.5119 - accuracy: 0.8274 - val_loss: 1.7296 - val_accuracy: 0.5532\n",
      "Epoch 720/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.5292 - accuracy: 0.8254 - val_loss: 1.7306 - val_accuracy: 0.5579\n",
      "Epoch 721/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5087 - accuracy: 0.8244 - val_loss: 1.7352 - val_accuracy: 0.5532\n",
      "Epoch 722/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4835 - accuracy: 0.8353 - val_loss: 1.7360 - val_accuracy: 0.5532\n",
      "Epoch 723/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5043 - accuracy: 0.8333 - val_loss: 1.7373 - val_accuracy: 0.5556\n",
      "Epoch 724/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4781 - accuracy: 0.8472 - val_loss: 1.7355 - val_accuracy: 0.5532\n",
      "Epoch 725/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4826 - accuracy: 0.8393 - val_loss: 1.7350 - val_accuracy: 0.5509\n",
      "Epoch 726/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.5017 - accuracy: 0.8244 - val_loss: 1.7308 - val_accuracy: 0.5532\n",
      "Epoch 727/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4918 - accuracy: 0.8274 - val_loss: 1.7355 - val_accuracy: 0.5556\n",
      "Epoch 728/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4875 - accuracy: 0.8383 - val_loss: 1.7379 - val_accuracy: 0.5509\n",
      "Epoch 729/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4824 - accuracy: 0.8393 - val_loss: 1.7367 - val_accuracy: 0.5602\n",
      "Epoch 730/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4766 - accuracy: 0.8462 - val_loss: 1.7334 - val_accuracy: 0.5579\n",
      "Epoch 731/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4858 - accuracy: 0.8363 - val_loss: 1.7334 - val_accuracy: 0.5556\n",
      "Epoch 732/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4885 - accuracy: 0.8403 - val_loss: 1.7343 - val_accuracy: 0.5556\n",
      "Epoch 733/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4812 - accuracy: 0.8403 - val_loss: 1.7330 - val_accuracy: 0.5556\n",
      "Epoch 734/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.5025 - accuracy: 0.8413 - val_loss: 1.7317 - val_accuracy: 0.5579\n",
      "Epoch 735/1000\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: 0.4882 - accuracy: 0.8472 - val_loss: 1.7313 - val_accuracy: 0.5602\n",
      "Epoch 736/1000\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: 0.4764 - accuracy: 0.8423 - val_loss: 1.7336 - val_accuracy: 0.5602\n",
      "Epoch 737/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4952 - accuracy: 0.8353 - val_loss: 1.7363 - val_accuracy: 0.5579\n",
      "Epoch 738/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4863 - accuracy: 0.8542 - val_loss: 1.7356 - val_accuracy: 0.5648\n",
      "Epoch 739/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4795 - accuracy: 0.8393 - val_loss: 1.7314 - val_accuracy: 0.5625\n",
      "Epoch 740/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4979 - accuracy: 0.8284 - val_loss: 1.7322 - val_accuracy: 0.5556\n",
      "Epoch 741/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4877 - accuracy: 0.8323 - val_loss: 1.7321 - val_accuracy: 0.5556\n",
      "Epoch 742/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4816 - accuracy: 0.8433 - val_loss: 1.7332 - val_accuracy: 0.5579\n",
      "Epoch 743/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4811 - accuracy: 0.8304 - val_loss: 1.7350 - val_accuracy: 0.5579\n",
      "Epoch 744/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4807 - accuracy: 0.8373 - val_loss: 1.7308 - val_accuracy: 0.5486\n",
      "Epoch 745/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4974 - accuracy: 0.8413 - val_loss: 1.7367 - val_accuracy: 0.5486\n",
      "Epoch 746/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4813 - accuracy: 0.8482 - val_loss: 1.7377 - val_accuracy: 0.5486\n",
      "Epoch 747/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4769 - accuracy: 0.8373 - val_loss: 1.7383 - val_accuracy: 0.5556\n",
      "Epoch 748/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4900 - accuracy: 0.8363 - val_loss: 1.7356 - val_accuracy: 0.5486\n",
      "Epoch 749/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4968 - accuracy: 0.8323 - val_loss: 1.7363 - val_accuracy: 0.5532\n",
      "Epoch 750/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4901 - accuracy: 0.8522 - val_loss: 1.7366 - val_accuracy: 0.5556\n",
      "Epoch 751/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4969 - accuracy: 0.8274 - val_loss: 1.7399 - val_accuracy: 0.5579\n",
      "Epoch 752/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4934 - accuracy: 0.8403 - val_loss: 1.7406 - val_accuracy: 0.5579\n",
      "Epoch 753/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4813 - accuracy: 0.8274 - val_loss: 1.7379 - val_accuracy: 0.5579\n",
      "Epoch 754/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.5161 - accuracy: 0.8135 - val_loss: 1.7375 - val_accuracy: 0.5579\n",
      "Epoch 755/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4959 - accuracy: 0.8383 - val_loss: 1.7359 - val_accuracy: 0.5602\n",
      "Epoch 756/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4781 - accuracy: 0.8403 - val_loss: 1.7370 - val_accuracy: 0.5579\n",
      "Epoch 757/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4903 - accuracy: 0.8433 - val_loss: 1.7400 - val_accuracy: 0.5625\n",
      "Epoch 758/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.5174 - accuracy: 0.8224 - val_loss: 1.7340 - val_accuracy: 0.5625\n",
      "Epoch 759/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4790 - accuracy: 0.8363 - val_loss: 1.7344 - val_accuracy: 0.5602\n",
      "Epoch 760/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4716 - accuracy: 0.8522 - val_loss: 1.7387 - val_accuracy: 0.5602\n",
      "Epoch 761/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4764 - accuracy: 0.8333 - val_loss: 1.7469 - val_accuracy: 0.5579\n",
      "Epoch 762/1000\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: 0.4773 - accuracy: 0.8353 - val_loss: 1.7423 - val_accuracy: 0.5579\n",
      "Epoch 763/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4817 - accuracy: 0.8383 - val_loss: 1.7429 - val_accuracy: 0.5602\n",
      "Epoch 764/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4780 - accuracy: 0.8343 - val_loss: 1.7407 - val_accuracy: 0.5556\n",
      "Epoch 765/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5027 - accuracy: 0.8274 - val_loss: 1.7388 - val_accuracy: 0.5602\n",
      "Epoch 766/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4978 - accuracy: 0.8274 - val_loss: 1.7385 - val_accuracy: 0.5579\n",
      "Epoch 767/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5197 - accuracy: 0.8442 - val_loss: 1.7395 - val_accuracy: 0.5625\n",
      "Epoch 768/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4830 - accuracy: 0.8413 - val_loss: 1.7380 - val_accuracy: 0.5625\n",
      "Epoch 769/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4968 - accuracy: 0.8304 - val_loss: 1.7381 - val_accuracy: 0.5648\n",
      "Epoch 770/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5234 - accuracy: 0.8284 - val_loss: 1.7370 - val_accuracy: 0.5602\n",
      "Epoch 771/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4974 - accuracy: 0.8383 - val_loss: 1.7341 - val_accuracy: 0.5579\n",
      "Epoch 772/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4958 - accuracy: 0.8403 - val_loss: 1.7338 - val_accuracy: 0.5625\n",
      "Epoch 773/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4620 - accuracy: 0.8482 - val_loss: 1.7352 - val_accuracy: 0.5648\n",
      "Epoch 774/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4756 - accuracy: 0.8423 - val_loss: 1.7368 - val_accuracy: 0.5648\n",
      "Epoch 775/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4771 - accuracy: 0.8373 - val_loss: 1.7369 - val_accuracy: 0.5625\n",
      "Epoch 776/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4941 - accuracy: 0.8403 - val_loss: 1.7349 - val_accuracy: 0.5648\n",
      "Epoch 777/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4879 - accuracy: 0.8393 - val_loss: 1.7358 - val_accuracy: 0.5625\n",
      "Epoch 778/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4880 - accuracy: 0.8313 - val_loss: 1.7362 - val_accuracy: 0.5602\n",
      "Epoch 779/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4797 - accuracy: 0.8413 - val_loss: 1.7361 - val_accuracy: 0.5625\n",
      "Epoch 780/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4698 - accuracy: 0.8413 - val_loss: 1.7365 - val_accuracy: 0.5579\n",
      "Epoch 781/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4907 - accuracy: 0.8333 - val_loss: 1.7362 - val_accuracy: 0.5556\n",
      "Epoch 782/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4740 - accuracy: 0.8383 - val_loss: 1.7362 - val_accuracy: 0.5648\n",
      "Epoch 783/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5026 - accuracy: 0.8254 - val_loss: 1.7379 - val_accuracy: 0.5602\n",
      "Epoch 784/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4653 - accuracy: 0.8442 - val_loss: 1.7372 - val_accuracy: 0.5625\n",
      "Epoch 785/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4744 - accuracy: 0.8244 - val_loss: 1.7377 - val_accuracy: 0.5556\n",
      "Epoch 786/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4670 - accuracy: 0.8403 - val_loss: 1.7375 - val_accuracy: 0.5579\n",
      "Epoch 787/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4721 - accuracy: 0.8452 - val_loss: 1.7373 - val_accuracy: 0.5579\n",
      "Epoch 788/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5101 - accuracy: 0.8403 - val_loss: 1.7389 - val_accuracy: 0.5579\n",
      "Epoch 789/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4947 - accuracy: 0.8353 - val_loss: 1.7370 - val_accuracy: 0.5532\n",
      "Epoch 790/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4885 - accuracy: 0.8313 - val_loss: 1.7365 - val_accuracy: 0.5486\n",
      "Epoch 791/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4854 - accuracy: 0.8462 - val_loss: 1.7370 - val_accuracy: 0.5579\n",
      "Epoch 792/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5036 - accuracy: 0.8343 - val_loss: 1.7362 - val_accuracy: 0.5556\n",
      "Epoch 793/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5090 - accuracy: 0.8333 - val_loss: 1.7362 - val_accuracy: 0.5532\n",
      "Epoch 794/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4881 - accuracy: 0.8373 - val_loss: 1.7332 - val_accuracy: 0.5602\n",
      "Epoch 795/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4858 - accuracy: 0.8383 - val_loss: 1.7329 - val_accuracy: 0.5602\n",
      "Epoch 796/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4923 - accuracy: 0.8333 - val_loss: 1.7326 - val_accuracy: 0.5556\n",
      "Epoch 797/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4836 - accuracy: 0.8383 - val_loss: 1.7364 - val_accuracy: 0.5556\n",
      "Epoch 798/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4765 - accuracy: 0.8373 - val_loss: 1.7374 - val_accuracy: 0.5486\n",
      "Epoch 799/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4812 - accuracy: 0.8393 - val_loss: 1.7367 - val_accuracy: 0.5532\n",
      "Epoch 800/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4670 - accuracy: 0.8472 - val_loss: 1.7353 - val_accuracy: 0.5532\n",
      "Epoch 801/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4804 - accuracy: 0.8423 - val_loss: 1.7353 - val_accuracy: 0.5509\n",
      "Epoch 802/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5043 - accuracy: 0.8333 - val_loss: 1.7358 - val_accuracy: 0.5625\n",
      "Epoch 803/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4709 - accuracy: 0.8423 - val_loss: 1.7380 - val_accuracy: 0.5579\n",
      "Epoch 804/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4921 - accuracy: 0.8343 - val_loss: 1.7405 - val_accuracy: 0.5579\n",
      "Epoch 805/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4933 - accuracy: 0.8462 - val_loss: 1.7383 - val_accuracy: 0.5625\n",
      "Epoch 806/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4777 - accuracy: 0.8194 - val_loss: 1.7390 - val_accuracy: 0.5602\n",
      "Epoch 807/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4721 - accuracy: 0.8462 - val_loss: 1.7423 - val_accuracy: 0.5532\n",
      "Epoch 808/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4733 - accuracy: 0.8413 - val_loss: 1.7406 - val_accuracy: 0.5625\n",
      "Epoch 809/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4671 - accuracy: 0.8452 - val_loss: 1.7406 - val_accuracy: 0.5509\n",
      "Epoch 810/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4815 - accuracy: 0.8393 - val_loss: 1.7408 - val_accuracy: 0.5532\n",
      "Epoch 811/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4891 - accuracy: 0.8313 - val_loss: 1.7366 - val_accuracy: 0.5486\n",
      "Epoch 812/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5210 - accuracy: 0.8413 - val_loss: 1.7363 - val_accuracy: 0.5602\n",
      "Epoch 813/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4787 - accuracy: 0.8403 - val_loss: 1.7360 - val_accuracy: 0.5579\n",
      "Epoch 814/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4687 - accuracy: 0.8353 - val_loss: 1.7386 - val_accuracy: 0.5602\n",
      "Epoch 815/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4759 - accuracy: 0.8353 - val_loss: 1.7359 - val_accuracy: 0.5532\n",
      "Epoch 816/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4968 - accuracy: 0.8343 - val_loss: 1.7365 - val_accuracy: 0.5579\n",
      "Epoch 817/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4697 - accuracy: 0.8562 - val_loss: 1.7387 - val_accuracy: 0.5532\n",
      "Epoch 818/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4757 - accuracy: 0.8462 - val_loss: 1.7416 - val_accuracy: 0.5532\n",
      "Epoch 819/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4616 - accuracy: 0.8472 - val_loss: 1.7424 - val_accuracy: 0.5579\n",
      "Epoch 820/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4841 - accuracy: 0.8323 - val_loss: 1.7404 - val_accuracy: 0.5532\n",
      "Epoch 821/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4680 - accuracy: 0.8433 - val_loss: 1.7395 - val_accuracy: 0.5579\n",
      "Epoch 822/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4888 - accuracy: 0.8333 - val_loss: 1.7412 - val_accuracy: 0.5602\n",
      "Epoch 823/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4594 - accuracy: 0.8512 - val_loss: 1.7415 - val_accuracy: 0.5602\n",
      "Epoch 824/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4642 - accuracy: 0.8562 - val_loss: 1.7395 - val_accuracy: 0.5556\n",
      "Epoch 825/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4898 - accuracy: 0.8373 - val_loss: 1.7401 - val_accuracy: 0.5532\n",
      "Epoch 826/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4943 - accuracy: 0.8403 - val_loss: 1.7390 - val_accuracy: 0.5509\n",
      "Epoch 827/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4503 - accuracy: 0.8522 - val_loss: 1.7422 - val_accuracy: 0.5486\n",
      "Epoch 828/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4754 - accuracy: 0.8363 - val_loss: 1.7423 - val_accuracy: 0.5532\n",
      "Epoch 829/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4849 - accuracy: 0.8304 - val_loss: 1.7418 - val_accuracy: 0.5556\n",
      "Epoch 830/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4699 - accuracy: 0.8343 - val_loss: 1.7448 - val_accuracy: 0.5579\n",
      "Epoch 831/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4805 - accuracy: 0.8313 - val_loss: 1.7428 - val_accuracy: 0.5556\n",
      "Epoch 832/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4789 - accuracy: 0.8393 - val_loss: 1.7404 - val_accuracy: 0.5509\n",
      "Epoch 833/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4828 - accuracy: 0.8413 - val_loss: 1.7412 - val_accuracy: 0.5486\n",
      "Epoch 834/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4817 - accuracy: 0.8423 - val_loss: 1.7412 - val_accuracy: 0.5509\n",
      "Epoch 835/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4826 - accuracy: 0.8383 - val_loss: 1.7435 - val_accuracy: 0.5556\n",
      "Epoch 836/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4756 - accuracy: 0.8393 - val_loss: 1.7440 - val_accuracy: 0.5486\n",
      "Epoch 837/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4715 - accuracy: 0.8433 - val_loss: 1.7427 - val_accuracy: 0.5532\n",
      "Epoch 838/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4914 - accuracy: 0.8403 - val_loss: 1.7400 - val_accuracy: 0.5532\n",
      "Epoch 839/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4710 - accuracy: 0.8462 - val_loss: 1.7397 - val_accuracy: 0.5556\n",
      "Epoch 840/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5043 - accuracy: 0.8363 - val_loss: 1.7402 - val_accuracy: 0.5579\n",
      "Epoch 841/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4511 - accuracy: 0.8462 - val_loss: 1.7386 - val_accuracy: 0.5556\n",
      "Epoch 842/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4746 - accuracy: 0.8363 - val_loss: 1.7381 - val_accuracy: 0.5556\n",
      "Epoch 843/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4933 - accuracy: 0.8522 - val_loss: 1.7395 - val_accuracy: 0.5509\n",
      "Epoch 844/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4922 - accuracy: 0.8323 - val_loss: 1.7400 - val_accuracy: 0.5602\n",
      "Epoch 845/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4702 - accuracy: 0.8482 - val_loss: 1.7406 - val_accuracy: 0.5556\n",
      "Epoch 846/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4928 - accuracy: 0.8363 - val_loss: 1.7402 - val_accuracy: 0.5532\n",
      "Epoch 847/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4779 - accuracy: 0.8254 - val_loss: 1.7408 - val_accuracy: 0.5509\n",
      "Epoch 848/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4597 - accuracy: 0.8571 - val_loss: 1.7384 - val_accuracy: 0.5532\n",
      "Epoch 849/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4548 - accuracy: 0.8532 - val_loss: 1.7378 - val_accuracy: 0.5509\n",
      "Epoch 850/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4750 - accuracy: 0.8373 - val_loss: 1.7372 - val_accuracy: 0.5509\n",
      "Epoch 851/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4861 - accuracy: 0.8462 - val_loss: 1.7361 - val_accuracy: 0.5532\n",
      "Epoch 852/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4687 - accuracy: 0.8363 - val_loss: 1.7393 - val_accuracy: 0.5532\n",
      "Epoch 853/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4644 - accuracy: 0.8502 - val_loss: 1.7411 - val_accuracy: 0.5532\n",
      "Epoch 854/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4925 - accuracy: 0.8313 - val_loss: 1.7422 - val_accuracy: 0.5509\n",
      "Epoch 855/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4694 - accuracy: 0.8423 - val_loss: 1.7429 - val_accuracy: 0.5556\n",
      "Epoch 856/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4669 - accuracy: 0.8482 - val_loss: 1.7425 - val_accuracy: 0.5509\n",
      "Epoch 857/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4436 - accuracy: 0.8601 - val_loss: 1.7448 - val_accuracy: 0.5532\n",
      "Epoch 858/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4662 - accuracy: 0.8472 - val_loss: 1.7426 - val_accuracy: 0.5556\n",
      "Epoch 859/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4659 - accuracy: 0.8413 - val_loss: 1.7424 - val_accuracy: 0.5532\n",
      "Epoch 860/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4585 - accuracy: 0.8482 - val_loss: 1.7406 - val_accuracy: 0.5509\n",
      "Epoch 861/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.8611 - val_loss: 1.7418 - val_accuracy: 0.5556\n",
      "Epoch 862/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4750 - accuracy: 0.8522 - val_loss: 1.7419 - val_accuracy: 0.5486\n",
      "Epoch 863/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4723 - accuracy: 0.8512 - val_loss: 1.7431 - val_accuracy: 0.5486\n",
      "Epoch 864/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4475 - accuracy: 0.8433 - val_loss: 1.7474 - val_accuracy: 0.5509\n",
      "Epoch 865/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4759 - accuracy: 0.8353 - val_loss: 1.7458 - val_accuracy: 0.5486\n",
      "Epoch 866/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4600 - accuracy: 0.8383 - val_loss: 1.7449 - val_accuracy: 0.5486\n",
      "Epoch 867/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4646 - accuracy: 0.8502 - val_loss: 1.7444 - val_accuracy: 0.5486\n",
      "Epoch 868/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4588 - accuracy: 0.8552 - val_loss: 1.7475 - val_accuracy: 0.5532\n",
      "Epoch 869/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4680 - accuracy: 0.8472 - val_loss: 1.7434 - val_accuracy: 0.5556\n",
      "Epoch 870/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5027 - accuracy: 0.8254 - val_loss: 1.7435 - val_accuracy: 0.5532\n",
      "Epoch 871/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4700 - accuracy: 0.8294 - val_loss: 1.7430 - val_accuracy: 0.5509\n",
      "Epoch 872/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4745 - accuracy: 0.8462 - val_loss: 1.7432 - val_accuracy: 0.5440\n",
      "Epoch 873/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4825 - accuracy: 0.8323 - val_loss: 1.7413 - val_accuracy: 0.5463\n",
      "Epoch 874/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4707 - accuracy: 0.8413 - val_loss: 1.7442 - val_accuracy: 0.5556\n",
      "Epoch 875/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4751 - accuracy: 0.8353 - val_loss: 1.7444 - val_accuracy: 0.5509\n",
      "Epoch 876/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4756 - accuracy: 0.8333 - val_loss: 1.7409 - val_accuracy: 0.5509\n",
      "Epoch 877/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4850 - accuracy: 0.8284 - val_loss: 1.7409 - val_accuracy: 0.5509\n",
      "Epoch 878/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4487 - accuracy: 0.8661 - val_loss: 1.7431 - val_accuracy: 0.5486\n",
      "Epoch 879/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4661 - accuracy: 0.8383 - val_loss: 1.7437 - val_accuracy: 0.5532\n",
      "Epoch 880/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5012 - accuracy: 0.8264 - val_loss: 1.7420 - val_accuracy: 0.5486\n",
      "Epoch 881/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4576 - accuracy: 0.8452 - val_loss: 1.7421 - val_accuracy: 0.5463\n",
      "Epoch 882/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4897 - accuracy: 0.8363 - val_loss: 1.7433 - val_accuracy: 0.5463\n",
      "Epoch 883/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4689 - accuracy: 0.8423 - val_loss: 1.7444 - val_accuracy: 0.5463\n",
      "Epoch 884/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4727 - accuracy: 0.8383 - val_loss: 1.7444 - val_accuracy: 0.5486\n",
      "Epoch 885/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4713 - accuracy: 0.8661 - val_loss: 1.7471 - val_accuracy: 0.5532\n",
      "Epoch 886/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4836 - accuracy: 0.8452 - val_loss: 1.7456 - val_accuracy: 0.5532\n",
      "Epoch 887/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4848 - accuracy: 0.8254 - val_loss: 1.7461 - val_accuracy: 0.5509\n",
      "Epoch 888/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4746 - accuracy: 0.8532 - val_loss: 1.7473 - val_accuracy: 0.5509\n",
      "Epoch 889/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4614 - accuracy: 0.8482 - val_loss: 1.7471 - val_accuracy: 0.5509\n",
      "Epoch 890/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4822 - accuracy: 0.8433 - val_loss: 1.7488 - val_accuracy: 0.5509\n",
      "Epoch 891/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4845 - accuracy: 0.8323 - val_loss: 1.7491 - val_accuracy: 0.5509\n",
      "Epoch 892/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4937 - accuracy: 0.8224 - val_loss: 1.7466 - val_accuracy: 0.5532\n",
      "Epoch 893/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4745 - accuracy: 0.8284 - val_loss: 1.7442 - val_accuracy: 0.5532\n",
      "Epoch 894/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4714 - accuracy: 0.8512 - val_loss: 1.7435 - val_accuracy: 0.5532\n",
      "Epoch 895/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4695 - accuracy: 0.8452 - val_loss: 1.7441 - val_accuracy: 0.5532\n",
      "Epoch 896/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4607 - accuracy: 0.8433 - val_loss: 1.7460 - val_accuracy: 0.5509\n",
      "Epoch 897/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4502 - accuracy: 0.8492 - val_loss: 1.7438 - val_accuracy: 0.5509\n",
      "Epoch 898/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4530 - accuracy: 0.8532 - val_loss: 1.7440 - val_accuracy: 0.5509\n",
      "Epoch 899/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4501 - accuracy: 0.8442 - val_loss: 1.7439 - val_accuracy: 0.5556\n",
      "Epoch 900/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4703 - accuracy: 0.8482 - val_loss: 1.7462 - val_accuracy: 0.5532\n",
      "Epoch 901/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4880 - accuracy: 0.8294 - val_loss: 1.7460 - val_accuracy: 0.5556\n",
      "Epoch 902/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4517 - accuracy: 0.8522 - val_loss: 1.7458 - val_accuracy: 0.5509\n",
      "Epoch 903/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4847 - accuracy: 0.8413 - val_loss: 1.7443 - val_accuracy: 0.5579\n",
      "Epoch 904/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4691 - accuracy: 0.8512 - val_loss: 1.7448 - val_accuracy: 0.5532\n",
      "Epoch 905/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4954 - accuracy: 0.8383 - val_loss: 1.7451 - val_accuracy: 0.5579\n",
      "Epoch 906/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4645 - accuracy: 0.8452 - val_loss: 1.7458 - val_accuracy: 0.5509\n",
      "Epoch 907/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4656 - accuracy: 0.8522 - val_loss: 1.7430 - val_accuracy: 0.5556\n",
      "Epoch 908/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4812 - accuracy: 0.8363 - val_loss: 1.7423 - val_accuracy: 0.5509\n",
      "Epoch 909/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4659 - accuracy: 0.8492 - val_loss: 1.7429 - val_accuracy: 0.5532\n",
      "Epoch 910/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4502 - accuracy: 0.8462 - val_loss: 1.7474 - val_accuracy: 0.5463\n",
      "Epoch 911/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4549 - accuracy: 0.8571 - val_loss: 1.7481 - val_accuracy: 0.5486\n",
      "Epoch 912/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4779 - accuracy: 0.8433 - val_loss: 1.7465 - val_accuracy: 0.5486\n",
      "Epoch 913/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4625 - accuracy: 0.8581 - val_loss: 1.7459 - val_accuracy: 0.5463\n",
      "Epoch 914/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4682 - accuracy: 0.8462 - val_loss: 1.7439 - val_accuracy: 0.5463\n",
      "Epoch 915/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4605 - accuracy: 0.8502 - val_loss: 1.7416 - val_accuracy: 0.5486\n",
      "Epoch 916/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4711 - accuracy: 0.8413 - val_loss: 1.7439 - val_accuracy: 0.5509\n",
      "Epoch 917/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4852 - accuracy: 0.8542 - val_loss: 1.7486 - val_accuracy: 0.5509\n",
      "Epoch 918/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.8442 - val_loss: 1.7476 - val_accuracy: 0.5486\n",
      "Epoch 919/1000\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: 0.4718 - accuracy: 0.8433 - val_loss: 1.7453 - val_accuracy: 0.5486\n",
      "Epoch 920/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4760 - accuracy: 0.8433 - val_loss: 1.7458 - val_accuracy: 0.5463\n",
      "Epoch 921/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4785 - accuracy: 0.8472 - val_loss: 1.7450 - val_accuracy: 0.5486\n",
      "Epoch 922/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4583 - accuracy: 0.8532 - val_loss: 1.7469 - val_accuracy: 0.5486\n",
      "Epoch 923/1000\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: 0.4639 - accuracy: 0.8502 - val_loss: 1.7436 - val_accuracy: 0.5486\n",
      "Epoch 924/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4565 - accuracy: 0.8462 - val_loss: 1.7456 - val_accuracy: 0.5509\n",
      "Epoch 925/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4489 - accuracy: 0.8552 - val_loss: 1.7471 - val_accuracy: 0.5509\n",
      "Epoch 926/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4672 - accuracy: 0.8363 - val_loss: 1.7464 - val_accuracy: 0.5509\n",
      "Epoch 927/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4790 - accuracy: 0.8373 - val_loss: 1.7478 - val_accuracy: 0.5509\n",
      "Epoch 928/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4558 - accuracy: 0.8413 - val_loss: 1.7488 - val_accuracy: 0.5556\n",
      "Epoch 929/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4528 - accuracy: 0.8532 - val_loss: 1.7504 - val_accuracy: 0.5556\n",
      "Epoch 930/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4809 - accuracy: 0.8442 - val_loss: 1.7512 - val_accuracy: 0.5509\n",
      "Epoch 931/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4678 - accuracy: 0.8472 - val_loss: 1.7517 - val_accuracy: 0.5509\n",
      "Epoch 932/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4526 - accuracy: 0.8502 - val_loss: 1.7517 - val_accuracy: 0.5556\n",
      "Epoch 933/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4542 - accuracy: 0.8492 - val_loss: 1.7513 - val_accuracy: 0.5532\n",
      "Epoch 934/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4484 - accuracy: 0.8482 - val_loss: 1.7510 - val_accuracy: 0.5509\n",
      "Epoch 935/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4646 - accuracy: 0.8482 - val_loss: 1.7500 - val_accuracy: 0.5486\n",
      "Epoch 936/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4536 - accuracy: 0.8492 - val_loss: 1.7494 - val_accuracy: 0.5532\n",
      "Epoch 937/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4481 - accuracy: 0.8492 - val_loss: 1.7492 - val_accuracy: 0.5486\n",
      "Epoch 938/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4513 - accuracy: 0.8542 - val_loss: 1.7508 - val_accuracy: 0.5509\n",
      "Epoch 939/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4734 - accuracy: 0.8363 - val_loss: 1.7523 - val_accuracy: 0.5509\n",
      "Epoch 940/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4533 - accuracy: 0.8581 - val_loss: 1.7519 - val_accuracy: 0.5556\n",
      "Epoch 941/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4548 - accuracy: 0.8442 - val_loss: 1.7510 - val_accuracy: 0.5532\n",
      "Epoch 942/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4994 - accuracy: 0.8383 - val_loss: 1.7514 - val_accuracy: 0.5579\n",
      "Epoch 943/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4658 - accuracy: 0.8452 - val_loss: 1.7540 - val_accuracy: 0.5509\n",
      "Epoch 944/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4674 - accuracy: 0.8413 - val_loss: 1.7565 - val_accuracy: 0.5556\n",
      "Epoch 945/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4512 - accuracy: 0.8522 - val_loss: 1.7548 - val_accuracy: 0.5532\n",
      "Epoch 946/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4709 - accuracy: 0.8403 - val_loss: 1.7545 - val_accuracy: 0.5532\n",
      "Epoch 947/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4671 - accuracy: 0.8452 - val_loss: 1.7539 - val_accuracy: 0.5532\n",
      "Epoch 948/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4712 - accuracy: 0.8413 - val_loss: 1.7535 - val_accuracy: 0.5556\n",
      "Epoch 949/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4883 - accuracy: 0.8363 - val_loss: 1.7520 - val_accuracy: 0.5509\n",
      "Epoch 950/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4564 - accuracy: 0.8591 - val_loss: 1.7525 - val_accuracy: 0.5556\n",
      "Epoch 951/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4642 - accuracy: 0.8462 - val_loss: 1.7531 - val_accuracy: 0.5486\n",
      "Epoch 952/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4689 - accuracy: 0.8403 - val_loss: 1.7524 - val_accuracy: 0.5532\n",
      "Epoch 953/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4622 - accuracy: 0.8512 - val_loss: 1.7519 - val_accuracy: 0.5556\n",
      "Epoch 954/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4628 - accuracy: 0.8353 - val_loss: 1.7507 - val_accuracy: 0.5509\n",
      "Epoch 955/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4376 - accuracy: 0.8581 - val_loss: 1.7523 - val_accuracy: 0.5532\n",
      "Epoch 956/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4575 - accuracy: 0.8462 - val_loss: 1.7532 - val_accuracy: 0.5556\n",
      "Epoch 957/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4913 - accuracy: 0.8353 - val_loss: 1.7559 - val_accuracy: 0.5556\n",
      "Epoch 958/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4674 - accuracy: 0.8413 - val_loss: 1.7554 - val_accuracy: 0.5556\n",
      "Epoch 959/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4811 - accuracy: 0.8284 - val_loss: 1.7538 - val_accuracy: 0.5486\n",
      "Epoch 960/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4635 - accuracy: 0.8433 - val_loss: 1.7534 - val_accuracy: 0.5532\n",
      "Epoch 961/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4453 - accuracy: 0.8413 - val_loss: 1.7540 - val_accuracy: 0.5509\n",
      "Epoch 962/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4447 - accuracy: 0.8611 - val_loss: 1.7535 - val_accuracy: 0.5509\n",
      "Epoch 963/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4412 - accuracy: 0.8562 - val_loss: 1.7545 - val_accuracy: 0.5556\n",
      "Epoch 964/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4622 - accuracy: 0.8512 - val_loss: 1.7535 - val_accuracy: 0.5556\n",
      "Epoch 965/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4501 - accuracy: 0.8502 - val_loss: 1.7541 - val_accuracy: 0.5532\n",
      "Epoch 966/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4648 - accuracy: 0.8472 - val_loss: 1.7536 - val_accuracy: 0.5532\n",
      "Epoch 967/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4796 - accuracy: 0.8472 - val_loss: 1.7557 - val_accuracy: 0.5532\n",
      "Epoch 968/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4665 - accuracy: 0.8284 - val_loss: 1.7573 - val_accuracy: 0.5556\n",
      "Epoch 969/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4563 - accuracy: 0.8482 - val_loss: 1.7541 - val_accuracy: 0.5579\n",
      "Epoch 970/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4661 - accuracy: 0.8542 - val_loss: 1.7583 - val_accuracy: 0.5579\n",
      "Epoch 971/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.5123 - accuracy: 0.8333 - val_loss: 1.7548 - val_accuracy: 0.5532\n",
      "Epoch 972/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4461 - accuracy: 0.8542 - val_loss: 1.7552 - val_accuracy: 0.5556\n",
      "Epoch 973/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4639 - accuracy: 0.8502 - val_loss: 1.7562 - val_accuracy: 0.5579\n",
      "Epoch 974/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4864 - accuracy: 0.8462 - val_loss: 1.7564 - val_accuracy: 0.5556\n",
      "Epoch 975/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4481 - accuracy: 0.8472 - val_loss: 1.7543 - val_accuracy: 0.5532\n",
      "Epoch 976/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4840 - accuracy: 0.8433 - val_loss: 1.7567 - val_accuracy: 0.5579\n",
      "Epoch 977/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4772 - accuracy: 0.8373 - val_loss: 1.7558 - val_accuracy: 0.5486\n",
      "Epoch 978/1000\n",
      "1008/1008 [==============================] - 3s 2ms/step - loss: 0.4576 - accuracy: 0.8462 - val_loss: 1.7562 - val_accuracy: 0.5579\n",
      "Epoch 979/1000\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 0.4857 - accuracy: 0.8383 - val_loss: 1.7558 - val_accuracy: 0.5556\n",
      "Epoch 980/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4496 - accuracy: 0.8442 - val_loss: 1.7580 - val_accuracy: 0.5579\n",
      "Epoch 981/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4728 - accuracy: 0.8452 - val_loss: 1.7555 - val_accuracy: 0.5556\n",
      "Epoch 982/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4705 - accuracy: 0.8393 - val_loss: 1.7590 - val_accuracy: 0.5579\n",
      "Epoch 983/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4571 - accuracy: 0.8333 - val_loss: 1.7588 - val_accuracy: 0.5579\n",
      "Epoch 984/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4565 - accuracy: 0.8502 - val_loss: 1.7569 - val_accuracy: 0.5556\n",
      "Epoch 985/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4383 - accuracy: 0.8532 - val_loss: 1.7599 - val_accuracy: 0.5579\n",
      "Epoch 986/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4493 - accuracy: 0.8452 - val_loss: 1.7559 - val_accuracy: 0.5579\n",
      "Epoch 987/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4625 - accuracy: 0.8522 - val_loss: 1.7567 - val_accuracy: 0.5532\n",
      "Epoch 988/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4613 - accuracy: 0.8393 - val_loss: 1.7580 - val_accuracy: 0.5532\n",
      "Epoch 989/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4578 - accuracy: 0.8512 - val_loss: 1.7573 - val_accuracy: 0.5532\n",
      "Epoch 990/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4531 - accuracy: 0.8403 - val_loss: 1.7593 - val_accuracy: 0.5532\n",
      "Epoch 991/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4660 - accuracy: 0.8442 - val_loss: 1.7588 - val_accuracy: 0.5532\n",
      "Epoch 992/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4544 - accuracy: 0.8512 - val_loss: 1.7581 - val_accuracy: 0.5532\n",
      "Epoch 993/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4715 - accuracy: 0.8294 - val_loss: 1.7564 - val_accuracy: 0.5532\n",
      "Epoch 994/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4852 - accuracy: 0.8333 - val_loss: 1.7571 - val_accuracy: 0.5509\n",
      "Epoch 995/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4457 - accuracy: 0.8472 - val_loss: 1.7574 - val_accuracy: 0.5532\n",
      "Epoch 996/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4937 - accuracy: 0.8274 - val_loss: 1.7549 - val_accuracy: 0.5509\n",
      "Epoch 997/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4508 - accuracy: 0.8502 - val_loss: 1.7539 - val_accuracy: 0.5532\n",
      "Epoch 998/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4522 - accuracy: 0.8532 - val_loss: 1.7545 - val_accuracy: 0.5532\n",
      "Epoch 999/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4978 - accuracy: 0.8274 - val_loss: 1.7533 - val_accuracy: 0.5532\n",
      "Epoch 1000/1000\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.4728 - accuracy: 0.8433 - val_loss: 1.7522 - val_accuracy: 0.5509\n"
     ]
    }
   ],
   "source": [
    "cnn_model=model.fit(x_traincnn, y_train, batch_size=16, epochs=1000, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the model loss\n",
    "\n",
    "plt.plot(cnn_model.history['loss'])\n",
    "plt.plot(cnn_model.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting model accuracy\n",
    "\n",
    "plt.plot(cnn_model.history['accuracy'])\n",
    "plt.plot(cnn_model.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(x_testcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 7, 7, 6, 2, 7, 4, 7, 0, 5, 7, 5, 6, 1, 7, 1, 5, 7, 4, 4, 5, 5,\n",
       "       3, 7, 4, 2, 7, 1, 6, 1, 6, 3, 6, 2, 1, 0, 4, 1, 7, 5, 1, 4, 1, 6,\n",
       "       7, 4, 7, 0, 4, 7, 3, 5, 4, 2, 6, 7, 7, 3, 3, 5, 2, 3, 1, 6, 2, 2,\n",
       "       3, 2, 5, 7, 5, 3, 4, 3, 2, 7, 7, 6, 2, 4, 7, 5, 2, 3, 7, 1, 7, 0,\n",
       "       1, 6, 7, 6, 7, 1, 3, 2, 3, 4, 7, 6, 2, 5, 3, 2, 0, 5, 0, 5, 0, 0,\n",
       "       6, 5, 0, 7, 1, 7, 2, 5, 1, 1, 2, 1, 5, 5, 7, 4, 6, 7, 3, 7, 1, 7,\n",
       "       2, 4, 6, 7, 7, 7, 1, 1, 7, 2, 6, 1, 7, 6, 1, 6, 7, 4, 6, 6, 1, 1,\n",
       "       1, 6, 4, 1, 4, 0, 5, 7, 5, 4, 6, 1, 5, 3, 3, 5, 5, 5, 5, 0, 7, 3,\n",
       "       3, 2, 6, 1, 6, 1, 7, 5, 4, 7, 1, 6, 5, 7, 7, 5, 5, 6, 2, 1, 6, 1,\n",
       "       6, 0, 1, 2, 7, 1, 6, 6, 6, 3, 3, 5, 6, 2, 3, 5, 1, 7, 6, 3, 4, 1,\n",
       "       4, 0, 2, 1, 1, 4, 1, 6, 0, 1, 2, 1, 6, 3, 2, 2, 1, 5, 1, 6, 4, 7,\n",
       "       2, 6, 6, 4, 7, 6, 6, 6, 2, 6, 6, 5, 1, 5, 6, 6, 5, 3, 5, 7, 1, 1,\n",
       "       6, 1, 3, 1, 3, 0, 1, 4, 2, 4, 6, 5, 7, 4, 3, 2, 2, 5, 1, 4, 0, 5,\n",
       "       7, 6, 1, 5, 5, 7, 7, 6, 3, 7, 2, 1, 2, 5, 1, 4, 5, 4, 2, 0, 3, 1,\n",
       "       2, 6, 6, 3, 4, 7, 7, 0, 5, 0, 4, 4, 1, 4, 6, 5, 2, 5, 1, 1, 2, 3,\n",
       "       2, 1, 4, 7, 3, 1, 6, 4, 3, 4, 1, 4, 0, 5, 2, 7, 2, 5, 7, 2, 6, 4,\n",
       "       0, 5, 6, 4, 3, 7, 2, 1, 5, 3, 0, 4, 2, 4, 0, 7, 5, 2, 5, 1, 7, 3,\n",
       "       0, 4, 3, 2, 7, 6, 1, 1, 0, 5, 2, 3, 4, 4, 3, 7, 1, 3, 7, 3, 7, 7,\n",
       "       3, 3, 5, 4, 1, 5, 5, 1, 7, 7, 1, 3, 2, 4, 5, 2, 4, 4, 4, 3, 5, 6,\n",
       "       5, 7, 4, 2, 1, 1, 2, 2, 1, 5, 4, 1, 7, 6])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 7, 6, 7, 7, 2, 4, 7, 0, 5, 2, 5, 4, 1, 7, 1, 5, 7, 4, 7, 5, 4,\n",
       "       6, 5, 3, 2, 7, 1, 0, 1, 2, 0, 6, 2, 1, 1, 4, 7, 3, 5, 1, 4, 1, 6,\n",
       "       2, 5, 7, 1, 4, 7, 2, 3, 4, 2, 6, 7, 7, 2, 3, 5, 5, 0, 1, 2, 2, 6,\n",
       "       0, 2, 5, 0, 5, 3, 3, 5, 6, 5, 2, 6, 2, 4, 7, 4, 2, 4, 7, 3, 7, 5,\n",
       "       6, 6, 6, 5, 7, 1, 1, 2, 3, 2, 7, 3, 2, 4, 5, 5, 7, 5, 5, 5, 6, 7,\n",
       "       6, 6, 0, 6, 0, 6, 5, 5, 1, 1, 7, 3, 5, 5, 7, 4, 4, 7, 3, 7, 1, 7,\n",
       "       5, 4, 6, 7, 5, 3, 3, 2, 7, 6, 4, 1, 7, 4, 1, 6, 4, 4, 6, 0, 6, 1,\n",
       "       0, 6, 4, 1, 4, 3, 5, 6, 3, 0, 6, 3, 2, 3, 3, 6, 3, 5, 5, 6, 5, 7,\n",
       "       3, 2, 5, 1, 6, 6, 7, 2, 3, 7, 1, 4, 3, 7, 7, 5, 3, 6, 6, 1, 6, 1,\n",
       "       6, 0, 0, 2, 7, 3, 6, 6, 3, 0, 4, 5, 6, 6, 1, 5, 1, 7, 1, 3, 4, 6,\n",
       "       4, 1, 4, 1, 1, 4, 1, 6, 3, 1, 2, 6, 6, 3, 2, 2, 3, 5, 3, 3, 4, 7,\n",
       "       1, 6, 6, 4, 2, 1, 3, 2, 3, 6, 6, 5, 1, 4, 7, 4, 5, 3, 5, 4, 1, 3,\n",
       "       6, 1, 2, 1, 3, 1, 1, 4, 2, 5, 6, 2, 7, 4, 7, 2, 2, 2, 0, 7, 0, 4,\n",
       "       7, 5, 1, 2, 7, 3, 5, 6, 1, 7, 2, 6, 2, 2, 1, 6, 5, 4, 2, 7, 5, 1,\n",
       "       2, 4, 6, 3, 4, 7, 4, 3, 5, 1, 4, 7, 1, 4, 7, 3, 2, 5, 0, 3, 2, 3,\n",
       "       2, 1, 4, 4, 0, 3, 6, 4, 6, 2, 1, 2, 3, 5, 0, 2, 5, 5, 4, 2, 6, 4,\n",
       "       7, 5, 6, 6, 6, 5, 6, 6, 5, 3, 3, 4, 2, 2, 0, 7, 5, 2, 3, 0, 7, 3,\n",
       "       1, 4, 3, 5, 0, 6, 1, 1, 0, 5, 7, 0, 4, 4, 3, 7, 3, 3, 7, 3, 6, 7,\n",
       "       3, 1, 5, 7, 2, 5, 2, 1, 6, 2, 0, 0, 5, 4, 2, 5, 2, 4, 4, 1, 3, 6,\n",
       "       5, 7, 4, 0, 1, 3, 5, 2, 1, 2, 4, 1, 7, 5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.22      0.23        27\n",
      "           1       0.59      0.74      0.66        57\n",
      "           2       0.55      0.49      0.52        57\n",
      "           3       0.43      0.36      0.39        56\n",
      "           4       0.67      0.64      0.65        55\n",
      "           5       0.58      0.57      0.58        61\n",
      "           6       0.57      0.53      0.55        62\n",
      "           7       0.57      0.68      0.62        57\n",
      "\n",
      "    accuracy                           0.55       432\n",
      "   macro avg       0.53      0.53      0.52       432\n",
      "weighted avg       0.55      0.55      0.55       432\n",
      "\n",
      "[[ 6  7  2  7  1  0  2  2]\n",
      " [ 6 42  1  6  0  0  2  0]\n",
      " [ 0  2 28  3  5  9  3  7]\n",
      " [ 5 12  1 20  3  8  4  3]\n",
      " [ 0  0  1  2 35  5  7  5]\n",
      " [ 2  0  9  3  2 35  4  6]\n",
      " [ 2  7  6  3  2  2 33  7]\n",
      " [ 4  1  3  2  4  1  3 39]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Layer Perceptron Classifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlpc = MLPClassifier(alpha=0.01, hidden_layer_sizes=(800,), learning_rate='adaptive', batch_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size=256, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(800,), learning_rate='adaptive',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the MLP model\n",
    "\n",
    "mlpc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpc_predictions = mlpc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.78      0.35        27\n",
      "           1       0.89      0.14      0.24        57\n",
      "           2       0.42      0.68      0.52        57\n",
      "           3       0.62      0.27      0.38        56\n",
      "           4       0.90      0.49      0.64        55\n",
      "           5       0.60      0.64      0.62        61\n",
      "           6       0.51      0.61      0.55        62\n",
      "           7       0.66      0.51      0.57        57\n",
      "\n",
      "    accuracy                           0.50       432\n",
      "   macro avg       0.60      0.52      0.48       432\n",
      "weighted avg       0.63      0.50      0.49       432\n",
      "\n",
      "[[21  0  3  1  0  0  0  2]\n",
      " [31  8  5  2  0  2  9  0]\n",
      " [ 3  0 39  1  1 10  2  1]\n",
      " [20  0  5 15  0 10  5  1]\n",
      " [ 4  0 10  0 27  2  8  4]\n",
      " [ 3  0  9  2  1 39  5  2]\n",
      " [ 4  1 10  3  1  0 38  5]\n",
      " [ 6  0 12  0  0  2  8 29]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,mlpc_predictions))\n",
    "print(confusion_matrix(y_test,mlpc_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
